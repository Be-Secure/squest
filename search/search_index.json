{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Squest Squest is a Web portal that allow to expose Ansible Tower based automation as a service. Features: Catalog of service that point to an Ansible Tower/AWX job template Admin approval on requests Instance lifecycle management (update, delete) If you want an idea of what you can do with Squest, click on the image below Create a new instance workflow Here is the workflow when a user ask for a new instance of a service. At the end of the creation, Tower uses the API to send information(spec) about the created instance. Specs related to the created instance are important in order to be sent later to a playbook in charge of updating this particular instance. Sent specs must contain unique IDs that allow to strongly identify the instance (E.g: uuid of a VMware VM) sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request service Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: Instance spec <br> {'uuid': 34, 'name': 'instance1'} Squest->>User: Notify service ready Update an existing instance workflow Here is the workflow when updating a service. Squest will automatically attach an extra_vars named squest that contains the instance spec sent by the playbook used to create the instance. The playbook used to update the instance need to use info placed in squest in order to retrieve the instance that need to be updated. The update playbook can send a new version of the instance to squest at the end of its process. sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request update Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process - Extra vars:<br> {'squest': {'uuid': 34, 'name': 'instance1'}} Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: New instance spec Squest->>User: Notify service updated","title":"Home"},{"location":"#squest","text":"Squest is a Web portal that allow to expose Ansible Tower based automation as a service. Features: Catalog of service that point to an Ansible Tower/AWX job template Admin approval on requests Instance lifecycle management (update, delete) If you want an idea of what you can do with Squest, click on the image below","title":"Squest"},{"location":"#create-a-new-instance-workflow","text":"Here is the workflow when a user ask for a new instance of a service. At the end of the creation, Tower uses the API to send information(spec) about the created instance. Specs related to the created instance are important in order to be sent later to a playbook in charge of updating this particular instance. Sent specs must contain unique IDs that allow to strongly identify the instance (E.g: uuid of a VMware VM) sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request service Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: Instance spec <br> {'uuid': 34, 'name': 'instance1'} Squest->>User: Notify service ready","title":"Create a new instance workflow"},{"location":"#update-an-existing-instance-workflow","text":"Here is the workflow when updating a service. Squest will automatically attach an extra_vars named squest that contains the instance spec sent by the playbook used to create the instance. The playbook used to update the instance need to use info placed in squest in order to retrieve the instance that need to be updated. The update playbook can send a new version of the instance to squest at the end of its process. sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request update Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process - Extra vars:<br> {'squest': {'uuid': 34, 'name': 'instance1'}} Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: New instance spec Squest->>User: Notify service updated","title":"Update an existing instance workflow"},{"location":"deployment/","text":"Deploy Squest The current deployment is based on Docker compose for testing the tool. Pre-requisites: docker docker-compose To test the application, run the full env docker compose file docker-compose -f dev-env.docker-compose.yml -f full-env.docker-compose.yml up Then connect with your web browser to http://127.0.0.1:8000 The default admin account is admin // admin","title":"Deployment"},{"location":"deployment/#deploy-squest","text":"The current deployment is based on Docker compose for testing the tool. Pre-requisites: docker docker-compose To test the application, run the full env docker compose file docker-compose -f dev-env.docker-compose.yml -f full-env.docker-compose.yml up Then connect with your web browser to http://127.0.0.1:8000 The default admin account is admin // admin","title":"Deploy Squest"},{"location":"settings/","text":"Configure settings Settings are placed into the squest/settings/development.py file which is a standard Django core settings file LDAP backend LDAP can be activated by setting the environment vairable LDAP_ENABLED to True or directly in the settings.py file: LDAP_ENABLED = True The configuration file need then to be created in Squest/ldap_config.py . The configuration is based on the Django plugin django-auth-ldap . You can follow the official documentation to know available configuration options. Example of ldap_config.py : import os import ldap from django_auth_ldap.config import LDAPSearch print ( \"LDAP config loaded\" ) # ----------------------- # LDAP auth backend # ----------------------- AUTH_LDAP_SERVER_URI = \"ldaps://ad.example.com\" AUTH_LDAP_BIND_DN = \"CN=my_app,OU=Service_Accounts,DC=example,DC=com\" AUTH_LDAP_BIND_PASSWORD = os . environ . get ( 'AUTH_LDAP_BIND_PASSWORD' , None ) AUTH_LDAP_USER_SEARCH = LDAPSearch ( \"OU=Service_Accounts,DC=example,DC=com\" , ldap . SCOPE_SUBTREE , \"(uid= %(user)s )\" ) LDAP_CA_FILE_PATH = \"/path/to/my/company-ca.crt\" AUTH_LDAP_CONNECTION_OPTIONS : { ldap . OPT_X_TLS_CACERTFILE : LDAP_CA_FILE_PATH , ldap . OPT_X_TLS_REQUIRE_CERT : ldap . OPT_X_TLS_ALLOW , ldap . OPT_X_TLS_NEWCTX : 0 } AUTH_LDAP_START_TLS : True AUTH_LDAP_USER_ATTR_MAP = { \"first_name\" : \"givenName\" , \"last_name\" : \"sn\" , \"email\" : \"uid\" } Email Email settings are based on the django settings EMAIL_HOST = os . environ . get ( 'EMAIL_HOST' , None ) EMAIL_PORT = 25","title":"Configuration"},{"location":"settings/#configure-settings","text":"Settings are placed into the squest/settings/development.py file which is a standard Django core settings file","title":"Configure settings"},{"location":"settings/#ldap-backend","text":"LDAP can be activated by setting the environment vairable LDAP_ENABLED to True or directly in the settings.py file: LDAP_ENABLED = True The configuration file need then to be created in Squest/ldap_config.py . The configuration is based on the Django plugin django-auth-ldap . You can follow the official documentation to know available configuration options. Example of ldap_config.py : import os import ldap from django_auth_ldap.config import LDAPSearch print ( \"LDAP config loaded\" ) # ----------------------- # LDAP auth backend # ----------------------- AUTH_LDAP_SERVER_URI = \"ldaps://ad.example.com\" AUTH_LDAP_BIND_DN = \"CN=my_app,OU=Service_Accounts,DC=example,DC=com\" AUTH_LDAP_BIND_PASSWORD = os . environ . get ( 'AUTH_LDAP_BIND_PASSWORD' , None ) AUTH_LDAP_USER_SEARCH = LDAPSearch ( \"OU=Service_Accounts,DC=example,DC=com\" , ldap . SCOPE_SUBTREE , \"(uid= %(user)s )\" ) LDAP_CA_FILE_PATH = \"/path/to/my/company-ca.crt\" AUTH_LDAP_CONNECTION_OPTIONS : { ldap . OPT_X_TLS_CACERTFILE : LDAP_CA_FILE_PATH , ldap . OPT_X_TLS_REQUIRE_CERT : ldap . OPT_X_TLS_ALLOW , ldap . OPT_X_TLS_NEWCTX : 0 } AUTH_LDAP_START_TLS : True AUTH_LDAP_USER_ATTR_MAP = { \"first_name\" : \"givenName\" , \"last_name\" : \"sn\" , \"email\" : \"uid\" }","title":"LDAP backend"},{"location":"settings/#email","text":"Email settings are based on the django settings EMAIL_HOST = os . environ . get ( 'EMAIL_HOST' , None ) EMAIL_PORT = 25","title":"Email"},{"location":"dev/dev-env/","text":"Setup a development environment Pre requisites Tools Following tools need to be installed on your workstation: Docker Docker-compose Python 3.8 Python virtualenv Poetry npm System packages Ubuntu based OS: sudo apt-get install libmysqlclient-dev CentOS/RedHat/Fedora sudo yum install mysql-devel Start a development environment The development environment is composed of 4 parts: Docker compose: The Docker compose file is used to deploy all required components such as the database and the message broker Celery worker: The Celery worker is a separated process that receive tasks from the main Django process to be executed asynchronously Celery beat: Celery beat is a periodic task scheduler that send task into the celery worker based on a frequency. This part is used by Squest to check the status of executed Tower job Django built in web server: Integrated web server used only for development purpose. main process of the application that serve the Web Ui and the API Docker compose Run the Docker dev env to bring up database, message broker and other required system docker-compose -f dev-env.docker-compose.yml up Python environment Initializing and installing python libraries with Poetry poetry install Go into the python virtual env poetry shell Create the database with Django migration script python manage.py migrate Collect static files python manage.py collectstatic --noinput Insert default data python manage.py insert_default_data Javascript libraries Install JS libs (npm need to be installed) npm install Celery worker and periodic task scheduler Run Celery process for async tasks from a new terminal poetry shell celery -A service_catalog worker -l info Run Celery beat for periodic tasks from a new terminal poetry shell celery -A service_catalog worker --beat --scheduler django -l info Django integrated web server This next command should be executed from your IDE. Run django dev server poetry shell python manage.py runserver Commands To clean all Celery pending tasks poetry shell celery -A restapi purge Execute tests Run unit tests poetry shell python manage.py test Run code coverage coverage run --source = '.' manage.py test coverage report","title":"Setup a dev env"},{"location":"dev/dev-env/#setup-a-development-environment","text":"","title":"Setup a development environment"},{"location":"dev/dev-env/#pre-requisites","text":"","title":"Pre requisites"},{"location":"dev/dev-env/#tools","text":"Following tools need to be installed on your workstation: Docker Docker-compose Python 3.8 Python virtualenv Poetry npm","title":"Tools"},{"location":"dev/dev-env/#system-packages","text":"Ubuntu based OS: sudo apt-get install libmysqlclient-dev CentOS/RedHat/Fedora sudo yum install mysql-devel","title":"System packages"},{"location":"dev/dev-env/#start-a-development-environment","text":"The development environment is composed of 4 parts: Docker compose: The Docker compose file is used to deploy all required components such as the database and the message broker Celery worker: The Celery worker is a separated process that receive tasks from the main Django process to be executed asynchronously Celery beat: Celery beat is a periodic task scheduler that send task into the celery worker based on a frequency. This part is used by Squest to check the status of executed Tower job Django built in web server: Integrated web server used only for development purpose. main process of the application that serve the Web Ui and the API","title":"Start a development environment"},{"location":"dev/dev-env/#docker-compose","text":"Run the Docker dev env to bring up database, message broker and other required system docker-compose -f dev-env.docker-compose.yml up","title":"Docker compose"},{"location":"dev/dev-env/#python-environment","text":"Initializing and installing python libraries with Poetry poetry install Go into the python virtual env poetry shell Create the database with Django migration script python manage.py migrate Collect static files python manage.py collectstatic --noinput Insert default data python manage.py insert_default_data","title":"Python environment"},{"location":"dev/dev-env/#javascript-libraries","text":"Install JS libs (npm need to be installed) npm install","title":"Javascript libraries"},{"location":"dev/dev-env/#celery-worker-and-periodic-task-scheduler","text":"Run Celery process for async tasks from a new terminal poetry shell celery -A service_catalog worker -l info Run Celery beat for periodic tasks from a new terminal poetry shell celery -A service_catalog worker --beat --scheduler django -l info","title":"Celery worker and periodic task scheduler"},{"location":"dev/dev-env/#django-integrated-web-server","text":"This next command should be executed from your IDE. Run django dev server poetry shell python manage.py runserver","title":"Django integrated web server"},{"location":"dev/dev-env/#commands","text":"To clean all Celery pending tasks poetry shell celery -A restapi purge","title":"Commands"},{"location":"dev/dev-env/#execute-tests","text":"Run unit tests poetry shell python manage.py test Run code coverage coverage run --source = '.' manage.py test coverage report","title":"Execute tests"},{"location":"dev/instance-state-machine/","text":"Instance state machine","title":"Instance state machine"},{"location":"dev/instance-state-machine/#instance-state-machine","text":"","title":"Instance state machine"},{"location":"dev/request-state-machine/","text":"Request state machine","title":"Request state machine"},{"location":"dev/request-state-machine/#request-state-machine","text":"","title":"Request state machine"}]}