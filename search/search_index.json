{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Squest Squest is a Web portal that allow to expose Ansible Tower based automation as a service. Features: Catalog of service that point to an Ansible Tower/AWX job template Admin approval on requests Instance lifecycle management (update, delete) If you want an idea of what you can do with Squest, click on the image below Create a new instance workflow Here is the workflow when a user ask for a new instance of a service. At the end of the creation, Tower uses the API to send information(spec) about the created instance. Specs related to the created instance are important in order to be sent later to a playbook in charge of updating this particular instance. Sent specs must contain unique IDs that allow to strongly identify the instance (E.g: uuid of a VMware VM) sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request service Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: Instance spec <br> {'uuid': 34, 'name': 'instance1'} Squest->>User: Notify service ready Update an existing instance workflow Here is the workflow when updating a service. Squest will automatically attach an extra_vars named squest that contains the instance spec sent by the playbook used to create the instance. The playbook used to update the instance need to use info placed in squest in order to retrieve the instance that need to be updated. The update playbook can send a new version of the instance to squest at the end of its process. sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request update Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process - Extra vars:<br> {'squest': {'uuid': 34, 'name': 'instance1'}} Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: New instance spec Squest->>User: Notify service updated","title":"Home"},{"location":"#squest","text":"Squest is a Web portal that allow to expose Ansible Tower based automation as a service. Features: Catalog of service that point to an Ansible Tower/AWX job template Admin approval on requests Instance lifecycle management (update, delete) If you want an idea of what you can do with Squest, click on the image below","title":"Squest"},{"location":"#create-a-new-instance-workflow","text":"Here is the workflow when a user ask for a new instance of a service. At the end of the creation, Tower uses the API to send information(spec) about the created instance. Specs related to the created instance are important in order to be sent later to a playbook in charge of updating this particular instance. Sent specs must contain unique IDs that allow to strongly identify the instance (E.g: uuid of a VMware VM) sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request service Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: Instance spec <br> {'uuid': 34, 'name': 'instance1'} Squest->>User: Notify service ready","title":"Create a new instance workflow"},{"location":"#update-an-existing-instance-workflow","text":"Here is the workflow when updating a service. Squest will automatically attach an extra_vars named squest that contains the instance spec sent by the playbook used to create the instance. The playbook used to update the instance need to use info placed in squest in order to retrieve the instance that need to be updated. The update playbook can send a new version of the instance to squest at the end of its process. sequenceDiagram participant User participant Admin participant Squest participant Tower User->>Squest: Request update Admin->>Squest: Approve Admin->>Squest: Process Squest->>Tower: Process - Extra vars:<br> {'squest': {'uuid': 34, 'name': 'instance1'}} Squest-->>Tower: Check Note right of Tower: Running Squest-->>Tower: Check Note right of Tower: Successful Tower->>Squest: New instance spec Squest->>User: Notify service updated","title":"Update an existing instance workflow"},{"location":"deployment/","text":"Deploy Squest The current deployment is based on Docker compose for testing the tool. Pre-requisites: docker docker-compose To test the application, run the full env docker compose file docker-compose -f dev-env.docker-compose.yml -f full-env.docker-compose.yml up Then connect with your web browser to http://127.0.0.1:8000 The default admin account is admin // admin","title":"Deployment"},{"location":"deployment/#deploy-squest","text":"The current deployment is based on Docker compose for testing the tool. Pre-requisites: docker docker-compose To test the application, run the full env docker compose file docker-compose -f dev-env.docker-compose.yml -f full-env.docker-compose.yml up Then connect with your web browser to http://127.0.0.1:8000 The default admin account is admin // admin","title":"Deploy Squest"},{"location":"settings/","text":"Configure settings Settings are placed into the squest/settings/development.py file which is a standard Django core settings file LDAP backend LDAP can be activated by setting the environment vairable LDAP_ENABLED to True or directly in the settings.py file: LDAP_ENABLED = True The configuration file need then to be created in Squest/ldap_config.py . The configuration is based on the Django plugin django-auth-ldap . You can follow the official documentation to know available configuration options. Example of ldap_config.py : import os import ldap from django_auth_ldap.config import LDAPSearch print ( \"LDAP config loaded\" ) # ----------------------- # LDAP auth backend # ----------------------- AUTH_LDAP_SERVER_URI = \"ldaps://ad.example.com\" AUTH_LDAP_BIND_DN = \"CN=my_app,OU=Service_Accounts,DC=example,DC=com\" AUTH_LDAP_BIND_PASSWORD = os . environ . get ( 'AUTH_LDAP_BIND_PASSWORD' , None ) AUTH_LDAP_USER_SEARCH = LDAPSearch ( \"OU=Service_Accounts,DC=example,DC=com\" , ldap . SCOPE_SUBTREE , \"(uid= %(user)s )\" ) LDAP_CA_FILE_PATH = \"/path/to/my/company-ca.crt\" AUTH_LDAP_CONNECTION_OPTIONS : { ldap . OPT_X_TLS_CACERTFILE : LDAP_CA_FILE_PATH , ldap . OPT_X_TLS_REQUIRE_CERT : ldap . OPT_X_TLS_ALLOW , ldap . OPT_X_TLS_NEWCTX : 0 } AUTH_LDAP_START_TLS : True AUTH_LDAP_USER_ATTR_MAP = { \"first_name\" : \"givenName\" , \"last_name\" : \"sn\" , \"email\" : \"uid\" } Email Email settings are based on the django settings EMAIL_HOST = os . environ . get ( 'EMAIL_HOST' , None ) EMAIL_PORT = 25","title":"Configuration"},{"location":"settings/#configure-settings","text":"Settings are placed into the squest/settings/development.py file which is a standard Django core settings file","title":"Configure settings"},{"location":"settings/#ldap-backend","text":"LDAP can be activated by setting the environment vairable LDAP_ENABLED to True or directly in the settings.py file: LDAP_ENABLED = True The configuration file need then to be created in Squest/ldap_config.py . The configuration is based on the Django plugin django-auth-ldap . You can follow the official documentation to know available configuration options. Example of ldap_config.py : import os import ldap from django_auth_ldap.config import LDAPSearch print ( \"LDAP config loaded\" ) # ----------------------- # LDAP auth backend # ----------------------- AUTH_LDAP_SERVER_URI = \"ldaps://ad.example.com\" AUTH_LDAP_BIND_DN = \"CN=my_app,OU=Service_Accounts,DC=example,DC=com\" AUTH_LDAP_BIND_PASSWORD = os . environ . get ( 'AUTH_LDAP_BIND_PASSWORD' , None ) AUTH_LDAP_USER_SEARCH = LDAPSearch ( \"OU=Service_Accounts,DC=example,DC=com\" , ldap . SCOPE_SUBTREE , \"(uid= %(user)s )\" ) LDAP_CA_FILE_PATH = \"/path/to/my/company-ca.crt\" AUTH_LDAP_CONNECTION_OPTIONS : { ldap . OPT_X_TLS_CACERTFILE : LDAP_CA_FILE_PATH , ldap . OPT_X_TLS_REQUIRE_CERT : ldap . OPT_X_TLS_ALLOW , ldap . OPT_X_TLS_NEWCTX : 0 } AUTH_LDAP_START_TLS : True AUTH_LDAP_USER_ATTR_MAP = { \"first_name\" : \"givenName\" , \"last_name\" : \"sn\" , \"email\" : \"uid\" }","title":"LDAP backend"},{"location":"settings/#email","text":"Email settings are based on the django settings EMAIL_HOST = os . environ . get ( 'EMAIL_HOST' , None ) EMAIL_PORT = 25","title":"Email"},{"location":"contribute/documentation/","text":"Contributing to the documentation The documentation is written in markdown and then generated with mkdocs . Required libraries are installed if you've followed the development environment documentation of the project. Graphs and diagrams are generated by the Mermaid library . Update the documentation in the docs folder placed in the root of the project. Run dev server locally to check the result mkdocs serve The page is available on http://127.0.0.1:8000 . Send a pull request then to propose your changes to the project.","title":"Documentation"},{"location":"contribute/documentation/#contributing-to-the-documentation","text":"The documentation is written in markdown and then generated with mkdocs . Required libraries are installed if you've followed the development environment documentation of the project. Graphs and diagrams are generated by the Mermaid library . Update the documentation in the docs folder placed in the root of the project. Run dev server locally to check the result mkdocs serve The page is available on http://127.0.0.1:8000 . Send a pull request then to propose your changes to the project.","title":"Contributing to the documentation"},{"location":"dev/db-erd/","text":"Database Entity Relationship Diagrams erDiagram TOWER_SERVER { string name string host string token bool secure bool ssl_verify } JOB_TEMPLATE { string name int tower_id json survey } OPERATION { string name string description enum type json enabled_survey_fields bool auto_accept bool auto_process int process_timeout_second } SERVICE { string name string description blob image } REQUEST { json fill_in_survey date date_submitted date date_complete int tower_job_id enum state datetime periodic_task_date_expire string failure_message } INSTANCE { string name json spec enum state } SUPPORT { string title enum state date date_opened date date_closed } REQUEST_MESSAGE { date date_message string content } SUPPORT_MESSAGE { date date_message string content } JOB_TEMPLATE ||--o{ TOWER_SERVER: has OPERATION ||--o{ JOB_TEMPLATE: has OPERATION ||--o{ SERVICE: has REQUEST ||--o{ OPERATION: has REQUEST |o--|| PERDIODIC_TASK: has REQUEST ||--o{ INSTANCE: has INSTANCE }|--o{ USER: has SUPPORT ||--o{ INSTANCE: has SUPPORT ||--o{ USER: openned_by REQUEST_MESSAGE ||--o{ REQUEST: has REQUEST_MESSAGE ||--o{ USER: from SUPPORT_MESSAGE ||--o{ SUPPORT: has SUPPORT_MESSAGE ||--o{ USER: from","title":"Database ERD"},{"location":"dev/db-erd/#database-entity-relationship-diagrams","text":"erDiagram TOWER_SERVER { string name string host string token bool secure bool ssl_verify } JOB_TEMPLATE { string name int tower_id json survey } OPERATION { string name string description enum type json enabled_survey_fields bool auto_accept bool auto_process int process_timeout_second } SERVICE { string name string description blob image } REQUEST { json fill_in_survey date date_submitted date date_complete int tower_job_id enum state datetime periodic_task_date_expire string failure_message } INSTANCE { string name json spec enum state } SUPPORT { string title enum state date date_opened date date_closed } REQUEST_MESSAGE { date date_message string content } SUPPORT_MESSAGE { date date_message string content } JOB_TEMPLATE ||--o{ TOWER_SERVER: has OPERATION ||--o{ JOB_TEMPLATE: has OPERATION ||--o{ SERVICE: has REQUEST ||--o{ OPERATION: has REQUEST |o--|| PERDIODIC_TASK: has REQUEST ||--o{ INSTANCE: has INSTANCE }|--o{ USER: has SUPPORT ||--o{ INSTANCE: has SUPPORT ||--o{ USER: openned_by REQUEST_MESSAGE ||--o{ REQUEST: has REQUEST_MESSAGE ||--o{ USER: from SUPPORT_MESSAGE ||--o{ SUPPORT: has SUPPORT_MESSAGE ||--o{ USER: from","title":"Database Entity Relationship Diagrams"},{"location":"dev/dev-env/","text":"Setup a development environment Pre requisites Tools Following tools need to be installed on your workstation: Docker Docker-compose Python 3.8 Python virtualenv Poetry npm System packages Ubuntu based OS: sudo apt-get install libmysqlclient-dev CentOS/RedHat/Fedora sudo yum install mysql-devel Start a development environment The development environment is composed of 4 parts: Docker compose: The Docker compose file is used to deploy all required components such as the database and the message broker Celery worker: The Celery worker is a separated process that receive tasks from the main Django process to be executed asynchronously Celery beat: Celery beat is a periodic task scheduler that send task into the celery worker based on a frequency. This part is used by Squest to check the status of executed Tower job Django built in web server: Integrated web server used only for development purpose. main process of the application that serve the Web Ui and the API Docker compose Run the Docker dev env to bring up database, message broker and other required system docker-compose -f dev-env.docker-compose.yml up Python environment Initializing and installing python libraries with Poetry poetry install Go into the python virtual env poetry shell Create the database with Django migration script python manage.py migrate Collect static files python manage.py collectstatic --noinput Insert default data python manage.py insert_default_data Javascript libraries Install JS libs (npm need to be installed) npm install Celery worker and periodic task scheduler Run Celery process for async tasks from a new terminal poetry shell celery -A service_catalog worker -l info Run Celery beat for periodic tasks from a new terminal poetry shell celery -A service_catalog worker --beat --scheduler django -l info Django integrated web server This next command should be executed from your IDE. Run django dev server poetry shell python manage.py runserver Commands To clean all Celery pending tasks poetry shell celery -A restapi purge Execute tests Run unit tests poetry shell python manage.py test Run code coverage coverage run --source = '.' manage.py test coverage report","title":"Setup a dev env"},{"location":"dev/dev-env/#setup-a-development-environment","text":"","title":"Setup a development environment"},{"location":"dev/dev-env/#pre-requisites","text":"","title":"Pre requisites"},{"location":"dev/dev-env/#tools","text":"Following tools need to be installed on your workstation: Docker Docker-compose Python 3.8 Python virtualenv Poetry npm","title":"Tools"},{"location":"dev/dev-env/#system-packages","text":"Ubuntu based OS: sudo apt-get install libmysqlclient-dev CentOS/RedHat/Fedora sudo yum install mysql-devel","title":"System packages"},{"location":"dev/dev-env/#start-a-development-environment","text":"The development environment is composed of 4 parts: Docker compose: The Docker compose file is used to deploy all required components such as the database and the message broker Celery worker: The Celery worker is a separated process that receive tasks from the main Django process to be executed asynchronously Celery beat: Celery beat is a periodic task scheduler that send task into the celery worker based on a frequency. This part is used by Squest to check the status of executed Tower job Django built in web server: Integrated web server used only for development purpose. main process of the application that serve the Web Ui and the API","title":"Start a development environment"},{"location":"dev/dev-env/#docker-compose","text":"Run the Docker dev env to bring up database, message broker and other required system docker-compose -f dev-env.docker-compose.yml up","title":"Docker compose"},{"location":"dev/dev-env/#python-environment","text":"Initializing and installing python libraries with Poetry poetry install Go into the python virtual env poetry shell Create the database with Django migration script python manage.py migrate Collect static files python manage.py collectstatic --noinput Insert default data python manage.py insert_default_data","title":"Python environment"},{"location":"dev/dev-env/#javascript-libraries","text":"Install JS libs (npm need to be installed) npm install","title":"Javascript libraries"},{"location":"dev/dev-env/#celery-worker-and-periodic-task-scheduler","text":"Run Celery process for async tasks from a new terminal poetry shell celery -A service_catalog worker -l info Run Celery beat for periodic tasks from a new terminal poetry shell celery -A service_catalog worker --beat --scheduler django -l info","title":"Celery worker and periodic task scheduler"},{"location":"dev/dev-env/#django-integrated-web-server","text":"This next command should be executed from your IDE. Run django dev server poetry shell python manage.py runserver","title":"Django integrated web server"},{"location":"dev/dev-env/#commands","text":"To clean all Celery pending tasks poetry shell celery -A restapi purge","title":"Commands"},{"location":"dev/dev-env/#execute-tests","text":"Run unit tests poetry shell python manage.py test Run code coverage coverage run --source = '.' manage.py test coverage report","title":"Execute tests"},{"location":"dev/instance-state-machine/","text":"Instance state machine graph TB start((Start)) start --> pending pending[PENDING] provisioning[PROVISIONING] provision_failed[PROVISION_FAILED] available[AVAILABLE] updating[UPDATING] update_failed[UPDATE_FAILED] deleting[DELETING] delete_failed[DELETE_FAILED] deleted[DELETED] archived[ARCHIVED] pending --> provisioning provision_ok{provision ok?} style provision_ok fill:#80CBC4 provisioning --> provision_ok provision_ok --> |No| provision_failed provision_ok --> |Yes| available provision_failed --> |retry| provisioning available --> |update| updating update_ok{update ok?} style update_ok fill:#80CBC4 updating --> update_ok update_ok --> |No| update_failed update_ok --> |Yes| available available --> |Delete| deleting deletion_ok{deletion ok?} style deletion_ok fill:#80CBC4 deleting --> deletion_ok deletion_ok --> |No| delete_failed deletion_ok --> |Yes| deleted deleted --> |archive| archived delete_failed --> |Retry| deleting","title":"Instance state machine"},{"location":"dev/instance-state-machine/#instance-state-machine","text":"graph TB start((Start)) start --> pending pending[PENDING] provisioning[PROVISIONING] provision_failed[PROVISION_FAILED] available[AVAILABLE] updating[UPDATING] update_failed[UPDATE_FAILED] deleting[DELETING] delete_failed[DELETE_FAILED] deleted[DELETED] archived[ARCHIVED] pending --> provisioning provision_ok{provision ok?} style provision_ok fill:#80CBC4 provisioning --> provision_ok provision_ok --> |No| provision_failed provision_ok --> |Yes| available provision_failed --> |retry| provisioning available --> |update| updating update_ok{update ok?} style update_ok fill:#80CBC4 updating --> update_ok update_ok --> |No| update_failed update_ok --> |Yes| available available --> |Delete| deleting deletion_ok{deletion ok?} style deletion_ok fill:#80CBC4 deleting --> deletion_ok deletion_ok --> |No| delete_failed deletion_ok --> |Yes| deleted deleted --> |archive| archived delete_failed --> |Retry| deleting","title":"Instance state machine"},{"location":"dev/request-state-machine/","text":"Request state machine graph TB start((Start)) submitted[SUBMITTED] start --> submitted auto_accept{auto accept?} style auto_accept fill:#80CBC4 instance_pending([instance pending]) submitted --> instance_pending instance_pending --> auto_accept accepted[ACCEPTED] auto_accept -->|Yes| accepted admin_action_1{admin action} style admin_action_1 fill:#80DEEA auto_accept -->|No| admin_action_1 need_info[NEED_INFO] admin_action_1 -->|need_info| need_info admin_action_1 -->|accept| accepted rejected[REJECTED] need_info -->|reject| rejected need_info -->|Submit| submitted canceled[CANCELED] need_info --> |cancel|canceled rejected --> |cancel|canceled submitted --> |cancel|canceled canceled --> |delete| deleted deleted((Deleted)) auto_pocess{auto process?} style auto_pocess fill:#80CBC4 accepted --> auto_pocess auto_pocess --> |Yes| operation_type admin_action_2{admin action} auto_pocess --> |No| admin_action_2 admin_action_2 --> |process| operation_type style admin_action_2 fill:#80DEEA operation_type{Operation type?} style operation_type fill:#80CBC4 instance_creating([instance_creating]) instance_updating([instance_updating]) instance_deleting([instance_deleting]) operation_type --> |CREATE| instance_creating operation_type --> |UPDATE| instance_updating operation_type --> |DELETE| instance_deleting processing[PROCESSING] instance_creating --> processing instance_updating --> processing instance_deleting --> processing processing_ok{processing ok?} style processing_ok fill:#80CBC4 processing --> processing_ok complete[COMPLETE] failed[FAILED] processing_ok --> |Yes| complete processing_ok --> |No| failed failed --> |retry| processing failed --> |cancel| accepted","title":"Request state machine"},{"location":"dev/request-state-machine/#request-state-machine","text":"graph TB start((Start)) submitted[SUBMITTED] start --> submitted auto_accept{auto accept?} style auto_accept fill:#80CBC4 instance_pending([instance pending]) submitted --> instance_pending instance_pending --> auto_accept accepted[ACCEPTED] auto_accept -->|Yes| accepted admin_action_1{admin action} style admin_action_1 fill:#80DEEA auto_accept -->|No| admin_action_1 need_info[NEED_INFO] admin_action_1 -->|need_info| need_info admin_action_1 -->|accept| accepted rejected[REJECTED] need_info -->|reject| rejected need_info -->|Submit| submitted canceled[CANCELED] need_info --> |cancel|canceled rejected --> |cancel|canceled submitted --> |cancel|canceled canceled --> |delete| deleted deleted((Deleted)) auto_pocess{auto process?} style auto_pocess fill:#80CBC4 accepted --> auto_pocess auto_pocess --> |Yes| operation_type admin_action_2{admin action} auto_pocess --> |No| admin_action_2 admin_action_2 --> |process| operation_type style admin_action_2 fill:#80DEEA operation_type{Operation type?} style operation_type fill:#80CBC4 instance_creating([instance_creating]) instance_updating([instance_updating]) instance_deleting([instance_deleting]) operation_type --> |CREATE| instance_creating operation_type --> |UPDATE| instance_updating operation_type --> |DELETE| instance_deleting processing[PROCESSING] instance_creating --> processing instance_updating --> processing instance_deleting --> processing processing_ok{processing ok?} style processing_ok fill:#80CBC4 processing --> processing_ok complete[COMPLETE] failed[FAILED] processing_ok --> |Yes| complete processing_ok --> |No| failed failed --> |retry| processing failed --> |cancel| accepted","title":"Request state machine"}]}