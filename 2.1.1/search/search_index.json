{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Squest Welcome to the Squest documentation! Squest is a self-service portal that works on top of Red Hat Ansible Automation Platform/AWX. Follow the installation guide to get your own deployment up and running Discuss with developers or the community on Gitter Chat Check out our GitHub repository if you are interested into contributing to Squest Don't hesitate to raise an issue to propose new features or raise a bug","title":"Home"},{"location":"#squest","text":"","title":"Squest"},{"location":"#welcome-to-the-squest-documentation","text":"Squest is a self-service portal that works on top of Red Hat Ansible Automation Platform/AWX. Follow the installation guide to get your own deployment up and running Discuss with developers or the community on Gitter Chat Check out our GitHub repository if you are interested into contributing to Squest Don't hesitate to raise an issue to propose new features or raise a bug","title":"Welcome to the Squest documentation!"},{"location":"getting_started/","text":"Pre-requisites: docker docker-compose Instance of Red Hat Ansible Automation Platform or AWX Deploy Squest The current deployment is based on Docker Compose. To run the application, execute the docker-compose.yml file: docker-compose up Then connect with your web browser to http://127.0.0.1:8080 The default admin account is admin // admin The default export the port 8080. If you want to use the standard HTTP port 80, update the file docker-compose.override.yml . services : nginx : ports : - \"80:8080\" Connect Squest to your controller The first step consist into adding a backend controller (RHAAP/AWX). In the left sidebar of Squest, go into the Administration group, look for the RHAAP/AWX item and follow the steps described in the administration documentation to add your controller. Once added, all Job templates present on the controller should appear in Squest. Create your first service Go into the Service catalog --> All Services and click on add a new service. The only mandatory information here is the name . Note For more information about the other flags, refer to service documentation . Once the service created, the next page invite you to create the first operation that will \"create\" an instance of this service. In this form, mandatory field are a name and selecting the job template to execute in the controller. Note For more information about the other flags, refer to operation documentation . Request your service Once the operation configured, the service is available in the catalog. Click on the order button of the service to create a new request . The first page ask to give an instance name which is a short name that will help you to identify and manage the lifecycle of the instance later. For example my_test_instance . In the second page, Squest will ask to fill all the variable that are present in the job template survey if one was attached. The request then appears in the Request tab. Click on the ID of the request to review it. The request detail page gives information about the current state of the request. From here you can accept, reject, cancel or update the filled fields. Once the request accepted, it can be processed, which means that the request is sent to the controller to execute the Job template . What next You know the basics of Squest. You can now dig into the service catalog documentation to learn the concept of services and operations. By default, Squest is deployed with a minimum configuration, this one can be customized by following the settings documentation.","title":"Getting Started"},{"location":"getting_started/#deploy-squest","text":"The current deployment is based on Docker Compose. To run the application, execute the docker-compose.yml file: docker-compose up Then connect with your web browser to http://127.0.0.1:8080 The default admin account is admin // admin The default export the port 8080. If you want to use the standard HTTP port 80, update the file docker-compose.override.yml . services : nginx : ports : - \"80:8080\"","title":"Deploy Squest"},{"location":"getting_started/#connect-squest-to-your-controller","text":"The first step consist into adding a backend controller (RHAAP/AWX). In the left sidebar of Squest, go into the Administration group, look for the RHAAP/AWX item and follow the steps described in the administration documentation to add your controller. Once added, all Job templates present on the controller should appear in Squest.","title":"Connect Squest to your controller"},{"location":"getting_started/#create-your-first-service","text":"Go into the Service catalog --> All Services and click on add a new service. The only mandatory information here is the name . Note For more information about the other flags, refer to service documentation . Once the service created, the next page invite you to create the first operation that will \"create\" an instance of this service. In this form, mandatory field are a name and selecting the job template to execute in the controller. Note For more information about the other flags, refer to operation documentation .","title":"Create your first service"},{"location":"getting_started/#request-your-service","text":"Once the operation configured, the service is available in the catalog. Click on the order button of the service to create a new request . The first page ask to give an instance name which is a short name that will help you to identify and manage the lifecycle of the instance later. For example my_test_instance . In the second page, Squest will ask to fill all the variable that are present in the job template survey if one was attached. The request then appears in the Request tab. Click on the ID of the request to review it. The request detail page gives information about the current state of the request. From here you can accept, reject, cancel or update the filled fields. Once the request accepted, it can be processed, which means that the request is sent to the controller to execute the Job template .","title":"Request your service"},{"location":"getting_started/#what-next","text":"You know the basics of Squest. You can now dig into the service catalog documentation to learn the concept of services and operations. By default, Squest is deployed with a minimum configuration, this one can be customized by following the settings documentation.","title":"What next"},{"location":"release_notes/","text":"Release Notes Squest releases are numbered as major, minor, and patch releases. For example, version 1.1.0 is a minor release, and 1.1.5 is a patch release. These can be described as follows: Major - Introduces or removes an entire API or other core functionality Minor - Implements major new features but may include breaking changes for API consumers or other integrations Patch - A maintenance release which fixes bugs and may introduce backward-compatible enhancements v2.0.0 This is a major update of Squest: The resource tracker component has been entirely refactored and cannot be migrated automatically The API has been reworked The previous team feature has been discontinued and replaced by an Organization/Team feature. Please note that teams data from v1 will be lost To migrate from v1 to v2 if you were using the resource tracking feature: Make sure that attribute definitions that are common (same type) are exactly the same name Follow the upgrade documentation to bump your current Squest installation to the last v1 version available: v1.10.5 Execute the resource tracker export script: docker-compose exec -T django python3 manage.py export_resource_tracker_v1 Follow the upgrade documentation to bump your installation to v2.X.X Execute the resource tracker import script: docker-compose exec -T django python3 manage.py import_resource_tracker_v1","title":"Release notes"},{"location":"release_notes/#release-notes","text":"Squest releases are numbered as major, minor, and patch releases. For example, version 1.1.0 is a minor release, and 1.1.5 is a patch release. These can be described as follows: Major - Introduces or removes an entire API or other core functionality Minor - Implements major new features but may include breaking changes for API consumers or other integrations Patch - A maintenance release which fixes bugs and may introduce backward-compatible enhancements","title":"Release Notes"},{"location":"release_notes/#v200","text":"This is a major update of Squest: The resource tracker component has been entirely refactored and cannot be migrated automatically The API has been reworked The previous team feature has been discontinued and replaced by an Organization/Team feature. Please note that teams data from v1 will be lost To migrate from v1 to v2 if you were using the resource tracking feature: Make sure that attribute definitions that are common (same type) are exactly the same name Follow the upgrade documentation to bump your current Squest installation to the last v1 version available: v1.10.5 Execute the resource tracker export script: docker-compose exec -T django python3 manage.py export_resource_tracker_v1 Follow the upgrade documentation to bump your installation to v2.X.X Execute the resource tracker import script: docker-compose exec -T django python3 manage.py import_resource_tracker_v1","title":"v2.0.0"},{"location":"administration/api/","text":"REST API Authentication Squest API allows tokens and session authentication. The API token management is available in the Tokens section of your profile page. A token is a unique identifier mapped to a Squest user account. Each user may have one or more tokens which can be used for authentication when making REST API requests. A token can have an expiration date to grant temporary access to an external client. Usage example with curl export SQUEST_TOKEN = d97ebdbeccf5fc3fba740e8e89048e3d453bd729 curl -X GET http://127.0.0.1:8000/api/resource-tracker/resource-group/ \\ -H \"Authorization: Bearer $SQUEST_TOKEN \" Usage example in Ansible URI module: - name : Get info from squest hosts : localhost connection : local gather_facts : false vars : squest_api : \"http://127.0.0.1:8000/api/\" squest_token : d97ebdbeccf5fc3fba740e8e89048e3d453bd729 squest_bearer_token : \"Bearer {{ squest_token }}\" tasks : - name : Get all resource group uri : url : \"{{ squest_api }}resource-tracker/resource-group/\" headers : Authorization : \"{{ squest_bearer_token }}\" method : GET status_code : 200 body_format : json register : output - debug : var : output API documentation The API documentation is available on the URL \"/swagger\" of your Squest instance. E.g: http://192.168.58.128/swagger/","title":"REST API"},{"location":"administration/api/#rest-api","text":"","title":"REST API"},{"location":"administration/api/#authentication","text":"Squest API allows tokens and session authentication. The API token management is available in the Tokens section of your profile page. A token is a unique identifier mapped to a Squest user account. Each user may have one or more tokens which can be used for authentication when making REST API requests. A token can have an expiration date to grant temporary access to an external client. Usage example with curl export SQUEST_TOKEN = d97ebdbeccf5fc3fba740e8e89048e3d453bd729 curl -X GET http://127.0.0.1:8000/api/resource-tracker/resource-group/ \\ -H \"Authorization: Bearer $SQUEST_TOKEN \" Usage example in Ansible URI module: - name : Get info from squest hosts : localhost connection : local gather_facts : false vars : squest_api : \"http://127.0.0.1:8000/api/\" squest_token : d97ebdbeccf5fc3fba740e8e89048e3d453bd729 squest_bearer_token : \"Bearer {{ squest_token }}\" tasks : - name : Get all resource group uri : url : \"{{ squest_api }}resource-tracker/resource-group/\" headers : Authorization : \"{{ squest_bearer_token }}\" method : GET status_code : 200 body_format : json register : output - debug : var : output","title":"Authentication"},{"location":"administration/api/#api-documentation","text":"The API documentation is available on the URL \"/swagger\" of your Squest instance. E.g: http://192.168.58.128/swagger/","title":"API documentation"},{"location":"administration/backup/","text":"Backup Persistent data of squest are: database media folder (used to store images) An integrated backup solution based on django-dbbackup is available. Once enabled, backups are placed in the /app/backup folder of the celery-beat container. Execute a backup manually Execute the command below against the celery-beat container: docker-compose exec celery-beat python manage.py dbbackup --clean docker-compose exec celery-beat python manage.py mediabackup --clean Get the backup list docker-compose exec celery-beat python manage.py listbackups Output example: Name Datetime default-3095326a6ee7-2021-09-10-112953.dump 09/10/21 11:29:53 3095326a6ee7-2021-09-10-113338.tar 09/10/21 11:33:38 Data are placed by default in a mounted volume named squest_backup . You can get the real path on the host by inspecting the volume: docker volume inspect squest_backup Output example: [ { \"CreatedAt\" : \"2021-09-13T09:42:26+02:00\" , \"Driver\" : \"local\" , \"Labels\" : { \"com.docker.compose.project\" : \"squest\" , \"com.docker.compose.version\" : \"1.28.4\" , \"com.docker.compose.volume\" : \"backup\" }, \"Mountpoint\" : \"/var/lib/docker/volumes/squest_backup/_data\" , \"Name\" : \"squest_backup\" , \"Options\" : null , \"Scope\" : \"local\" } ] In this example, data are placed in the mount point /var/lib/docker/volumes/squest_backup/_data on the host. Files in this path need to be placed in a safe place. Enable automatic backup Enable automatic backup by updating your environment configuration file docker/environment_variables/squest.env : BACKUP_ENABLED = True By default, backup is performed every day at 1 AM. Note Follow the full configuration documentation to know all available flags for the backup service. Restore Start Squest services like for the initial deployment docker-compose up Copy you backup files into the squest_backup mount point of your host sudo cp <backup_folder_path>/* <squest_backup_mount_point> E.g: sudo cp ~/Desktop/squest_backup/* /var/lib/docker/volumes/squest_backup/_data/ Check that the tool can list your backup files docker-compose exec celery-beat python manage.py listbackups Restore the database and media folder docker-compose exec celery-beat python manage.py dbrestore docker-compose exec celery-beat python manage.py mediarestore Note Get more info on dbrestore and mediarestore command arguments on the official doc .","title":"Backup"},{"location":"administration/backup/#backup","text":"Persistent data of squest are: database media folder (used to store images) An integrated backup solution based on django-dbbackup is available. Once enabled, backups are placed in the /app/backup folder of the celery-beat container.","title":"Backup"},{"location":"administration/backup/#execute-a-backup-manually","text":"Execute the command below against the celery-beat container: docker-compose exec celery-beat python manage.py dbbackup --clean docker-compose exec celery-beat python manage.py mediabackup --clean Get the backup list docker-compose exec celery-beat python manage.py listbackups Output example: Name Datetime default-3095326a6ee7-2021-09-10-112953.dump 09/10/21 11:29:53 3095326a6ee7-2021-09-10-113338.tar 09/10/21 11:33:38 Data are placed by default in a mounted volume named squest_backup . You can get the real path on the host by inspecting the volume: docker volume inspect squest_backup Output example: [ { \"CreatedAt\" : \"2021-09-13T09:42:26+02:00\" , \"Driver\" : \"local\" , \"Labels\" : { \"com.docker.compose.project\" : \"squest\" , \"com.docker.compose.version\" : \"1.28.4\" , \"com.docker.compose.volume\" : \"backup\" }, \"Mountpoint\" : \"/var/lib/docker/volumes/squest_backup/_data\" , \"Name\" : \"squest_backup\" , \"Options\" : null , \"Scope\" : \"local\" } ] In this example, data are placed in the mount point /var/lib/docker/volumes/squest_backup/_data on the host. Files in this path need to be placed in a safe place.","title":"Execute a backup manually"},{"location":"administration/backup/#enable-automatic-backup","text":"Enable automatic backup by updating your environment configuration file docker/environment_variables/squest.env : BACKUP_ENABLED = True By default, backup is performed every day at 1 AM. Note Follow the full configuration documentation to know all available flags for the backup service.","title":"Enable automatic backup"},{"location":"administration/backup/#restore","text":"Start Squest services like for the initial deployment docker-compose up Copy you backup files into the squest_backup mount point of your host sudo cp <backup_folder_path>/* <squest_backup_mount_point> E.g: sudo cp ~/Desktop/squest_backup/* /var/lib/docker/volumes/squest_backup/_data/ Check that the tool can list your backup files docker-compose exec celery-beat python manage.py listbackups Restore the database and media folder docker-compose exec celery-beat python manage.py dbrestore docker-compose exec celery-beat python manage.py mediarestore Note Get more info on dbrestore and mediarestore command arguments on the official doc .","title":"Restore"},{"location":"administration/metrics/","text":"Prometheus metrics Squest supports optionally exposing native Prometheus metrics from the application. Prometheus is a popular time series metric platform used for monitoring. Squest exposes metrics at the /metrics HTTP endpoint, e.g. https://squest.domain.local/metrics. Squest config Metrics page is disabled by default. Update your docker/environment_variables/squest.env to enable metrics. METRICS_ENABLED = True METRICS_PASSWORD_PROTECTED = True METRICS_AUTHORIZATION_USERNAME = admin METRICS_AUTHORIZATION_PASSWORD = my_secret_password Prometheus config Here is an example of prometheus configuration you can use to scrape squest metrics scrape_configs : - job_name : 'squest' scrape_interval : 30s metrics_path : '/metrics/' static_configs : - targets : [ 'squest.domain.local' ] scheme : http basic_auth : username : admin password : my_secret_password Exported metrics squest_instance_per_service_total Expose the total number of instance per service. Labels: ['service'] E.g: squest_instance_per_service_total{service=\"Kubernetes\"} 5.0 squest_instance_per_service_total{service=\"Openshift\"} 11.0 squest_instance_per_service_total{service=\"VMWare\"} 14.0 squest_instance_per_state_total Expose the total number of instance per state. Labels: ['state'] E.g: squest_instance_per_state_total{state=\"AVAILABLE\"} 2.0 squest_instance_per_state_total{state=\"PENDING\"} 28.0 squest_request_per_state_total Expose the total number of request per state. Labels: ['state'] E.g: squest_request_per_state_total{state=\"ACCEPTED\"} 4.0 squest_request_per_state_total{state=\"CANCELED\"} 3.0 squest_request_per_state_total{state=\"COMPLETE\"} 5.0 squest_request_per_state_total{state=\"FAILED\"} 4.0 squest_request_per_state_total{state=\"NEED_INFO\"} 2.0 squest_request_per_state_total{state=\"PROCESSING\"} 3.0 squest_request_per_state_total{state=\"REJECTED\"} 5.0 squest_request_per_state_total{state=\"SUBMITTED\"} 4.00 squest_instance_total Total number of instance in squest Labels: ['service', 'state', 'billing_group'] E.g: squest_instance_total{billing_group=\"Orchestration\",service=\"VMWare\",state=\"AVAILABLE\"} 1.0 squest_instance_total{billing_group=\"Assurance\",service=\"VMWare\",state=\"AVAILABLE\"} 1.0 squest_instance_total{billing_group=\"Orchestration\",service=\"VMWare\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"5G\",service=\"VMWare\",state=\"PENDING\"} 6.0 squest_instance_total{billing_group=\"Assurance\",service=\"VMWare\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"Assurance\",service=\"Openshift\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"5G\",service=\"Openshift\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"Orchestration\",service=\"Openshift\",state=\"PENDING\"} 4.0 squest_instance_total{billing_group=\"Orchestration\",service=\"Kubernetes\",state=\"PENDING\"} 1.0 squest_instance_total{billing_group=\"5G\",service=\"Kubernetes\",state=\"PENDING\"} 2.0 squest_instance_total{billing_group=\"Assurance\",service=\"Kubernetes\",state=\"PENDING\"} 2.0 squest_instance_total{billing_group=\"None\",service=\"Openshift\",state=\"PENDING\"} 1.0 squest_request_total Total number of request in squest Labels: ['service', 'state'] E.g: squest_request_total{service=\"VMWare\",state=\"COMPLETE\"} 3.0 squest_request_total{service=\"VMWare\",state=\"PROCESSING\"} 2.0 squest_request_total{service=\"VMWare\",state=\"ACCEPTED\"} 2.0 squest_request_total{service=\"VMWare\",state=\"NEED_INFO\"} 1.0 squest_request_total{service=\"VMWare\",state=\"REJECTED\"} 4.0 squest_request_total{service=\"VMWare\",state=\"SUBMITTED\"} 1.0 squest_request_total{service=\"VMWare\",state=\"FAILED\"} 1.0 squest_request_total{service=\"Openshift\",state=\"REJECTED\"} 1.0 squest_request_total{service=\"Openshift\",state=\"CANCELED\"} 2.0 squest_request_total{service=\"Openshift\",state=\"FAILED\"} 3.0 squest_request_total{service=\"Openshift\",state=\"COMPLETE\"} 1.0 squest_request_total{service=\"Openshift\",state=\"SUBMITTED\"} 2.0 squest_request_total{service=\"Openshift\",state=\"ACCEPTED\"} 2.0 squest_request_total{service=\"Kubernetes\",state=\"SUBMITTED\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"COMPLETE\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"CANCELED\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"PROCESSING\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"NEED_INFO\"} 1.0 squest_support_total Total number of support Labels: ['state'] E.g: squest_support_total{service=\"VMWare\",state=\"CLOSED\"} 2.0 squest_support_total{service=\"VMWare\",state=\"OPENED\"} 1.0 squest_user_total Total number of user Labels: ['is_superuser'] E.g: squest_user_total{is_superuser=\"true\"} 1.0 squest_user_total{is_superuser=\"false\"} 6.0 squest_team_total Total number of team E.g: squest_team_total 3.0 squest_billing_group_total Total number of team E.g: squest_billing_group_total 3.0 squest_quota_consumed Consumption of quota per billing group and attribute E.g: squest_quota_consumed{billing_group=\"5G\",quota_attribute=\"CPU\"} 22.0 squest_quota_consumed{billing_group=\"5G\",quota_attribute=\"Memory\"} 45.0 squest_quota_consumed{billing_group=\"Assurance\",quota_attribute=\"CPU\"} 20.0 squest_quota_consumed{billing_group=\"Assurance\",quota_attribute=\"Memory\"} 23.0 squest_quota_limit Limit of quota per billing group and attribute squest_quota_limit{billing_group=\"5G\",quota_attribute=\"CPU\"} 100.0 squest_quota_limit{billing_group=\"5G\",quota_attribute=\"Memory\"} 50.0 squest_quota_limit{billing_group=\"Assurance\",quota_attribute=\"CPU\"} 45.0 squest_quota_limit{billing_group=\"Assurance\",quota_attribute=\"Memory\"} 12.0) A percentage of consumption can be calculated by using squest_quota_consumed and squest_quota_limit . PromQL example: round((squest_quota_consumed / squest_quota_limit) * 100)","title":"Prometheus metrics"},{"location":"administration/metrics/#prometheus-metrics","text":"Squest supports optionally exposing native Prometheus metrics from the application. Prometheus is a popular time series metric platform used for monitoring. Squest exposes metrics at the /metrics HTTP endpoint, e.g. https://squest.domain.local/metrics.","title":"Prometheus metrics"},{"location":"administration/metrics/#squest-config","text":"Metrics page is disabled by default. Update your docker/environment_variables/squest.env to enable metrics. METRICS_ENABLED = True METRICS_PASSWORD_PROTECTED = True METRICS_AUTHORIZATION_USERNAME = admin METRICS_AUTHORIZATION_PASSWORD = my_secret_password","title":"Squest config"},{"location":"administration/metrics/#prometheus-config","text":"Here is an example of prometheus configuration you can use to scrape squest metrics scrape_configs : - job_name : 'squest' scrape_interval : 30s metrics_path : '/metrics/' static_configs : - targets : [ 'squest.domain.local' ] scheme : http basic_auth : username : admin password : my_secret_password","title":"Prometheus config"},{"location":"administration/metrics/#exported-metrics","text":"","title":"Exported metrics"},{"location":"administration/metrics/#squest_instance_per_service_total","text":"Expose the total number of instance per service. Labels: ['service'] E.g: squest_instance_per_service_total{service=\"Kubernetes\"} 5.0 squest_instance_per_service_total{service=\"Openshift\"} 11.0 squest_instance_per_service_total{service=\"VMWare\"} 14.0","title":"squest_instance_per_service_total"},{"location":"administration/metrics/#squest_instance_per_state_total","text":"Expose the total number of instance per state. Labels: ['state'] E.g: squest_instance_per_state_total{state=\"AVAILABLE\"} 2.0 squest_instance_per_state_total{state=\"PENDING\"} 28.0","title":"squest_instance_per_state_total"},{"location":"administration/metrics/#squest_request_per_state_total","text":"Expose the total number of request per state. Labels: ['state'] E.g: squest_request_per_state_total{state=\"ACCEPTED\"} 4.0 squest_request_per_state_total{state=\"CANCELED\"} 3.0 squest_request_per_state_total{state=\"COMPLETE\"} 5.0 squest_request_per_state_total{state=\"FAILED\"} 4.0 squest_request_per_state_total{state=\"NEED_INFO\"} 2.0 squest_request_per_state_total{state=\"PROCESSING\"} 3.0 squest_request_per_state_total{state=\"REJECTED\"} 5.0 squest_request_per_state_total{state=\"SUBMITTED\"} 4.00","title":"squest_request_per_state_total"},{"location":"administration/metrics/#squest_instance_total","text":"Total number of instance in squest Labels: ['service', 'state', 'billing_group'] E.g: squest_instance_total{billing_group=\"Orchestration\",service=\"VMWare\",state=\"AVAILABLE\"} 1.0 squest_instance_total{billing_group=\"Assurance\",service=\"VMWare\",state=\"AVAILABLE\"} 1.0 squest_instance_total{billing_group=\"Orchestration\",service=\"VMWare\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"5G\",service=\"VMWare\",state=\"PENDING\"} 6.0 squest_instance_total{billing_group=\"Assurance\",service=\"VMWare\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"Assurance\",service=\"Openshift\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"5G\",service=\"Openshift\",state=\"PENDING\"} 3.0 squest_instance_total{billing_group=\"Orchestration\",service=\"Openshift\",state=\"PENDING\"} 4.0 squest_instance_total{billing_group=\"Orchestration\",service=\"Kubernetes\",state=\"PENDING\"} 1.0 squest_instance_total{billing_group=\"5G\",service=\"Kubernetes\",state=\"PENDING\"} 2.0 squest_instance_total{billing_group=\"Assurance\",service=\"Kubernetes\",state=\"PENDING\"} 2.0 squest_instance_total{billing_group=\"None\",service=\"Openshift\",state=\"PENDING\"} 1.0","title":"squest_instance_total"},{"location":"administration/metrics/#squest_request_total","text":"Total number of request in squest Labels: ['service', 'state'] E.g: squest_request_total{service=\"VMWare\",state=\"COMPLETE\"} 3.0 squest_request_total{service=\"VMWare\",state=\"PROCESSING\"} 2.0 squest_request_total{service=\"VMWare\",state=\"ACCEPTED\"} 2.0 squest_request_total{service=\"VMWare\",state=\"NEED_INFO\"} 1.0 squest_request_total{service=\"VMWare\",state=\"REJECTED\"} 4.0 squest_request_total{service=\"VMWare\",state=\"SUBMITTED\"} 1.0 squest_request_total{service=\"VMWare\",state=\"FAILED\"} 1.0 squest_request_total{service=\"Openshift\",state=\"REJECTED\"} 1.0 squest_request_total{service=\"Openshift\",state=\"CANCELED\"} 2.0 squest_request_total{service=\"Openshift\",state=\"FAILED\"} 3.0 squest_request_total{service=\"Openshift\",state=\"COMPLETE\"} 1.0 squest_request_total{service=\"Openshift\",state=\"SUBMITTED\"} 2.0 squest_request_total{service=\"Openshift\",state=\"ACCEPTED\"} 2.0 squest_request_total{service=\"Kubernetes\",state=\"SUBMITTED\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"COMPLETE\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"CANCELED\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"PROCESSING\"} 1.0 squest_request_total{service=\"Kubernetes\",state=\"NEED_INFO\"} 1.0","title":"squest_request_total"},{"location":"administration/metrics/#squest_support_total","text":"Total number of support Labels: ['state'] E.g: squest_support_total{service=\"VMWare\",state=\"CLOSED\"} 2.0 squest_support_total{service=\"VMWare\",state=\"OPENED\"} 1.0","title":"squest_support_total"},{"location":"administration/metrics/#squest_user_total","text":"Total number of user Labels: ['is_superuser'] E.g: squest_user_total{is_superuser=\"true\"} 1.0 squest_user_total{is_superuser=\"false\"} 6.0","title":"squest_user_total"},{"location":"administration/metrics/#squest_team_total","text":"Total number of team E.g: squest_team_total 3.0","title":"squest_team_total"},{"location":"administration/metrics/#squest_billing_group_total","text":"Total number of team E.g: squest_billing_group_total 3.0","title":"squest_billing_group_total"},{"location":"administration/metrics/#squest_quota_consumed","text":"Consumption of quota per billing group and attribute E.g: squest_quota_consumed{billing_group=\"5G\",quota_attribute=\"CPU\"} 22.0 squest_quota_consumed{billing_group=\"5G\",quota_attribute=\"Memory\"} 45.0 squest_quota_consumed{billing_group=\"Assurance\",quota_attribute=\"CPU\"} 20.0 squest_quota_consumed{billing_group=\"Assurance\",quota_attribute=\"Memory\"} 23.0","title":"squest_quota_consumed"},{"location":"administration/metrics/#squest_quota_limit","text":"Limit of quota per billing group and attribute squest_quota_limit{billing_group=\"5G\",quota_attribute=\"CPU\"} 100.0 squest_quota_limit{billing_group=\"5G\",quota_attribute=\"Memory\"} 50.0 squest_quota_limit{billing_group=\"Assurance\",quota_attribute=\"CPU\"} 45.0 squest_quota_limit{billing_group=\"Assurance\",quota_attribute=\"Memory\"} 12.0) A percentage of consumption can be calculated by using squest_quota_consumed and squest_quota_limit . PromQL example: round((squest_quota_consumed / squest_quota_limit) * 100)","title":"squest_quota_limit"},{"location":"administration/upgrade/","text":"Squest upgrade This documentation aims at explaining how to perform an upgrade of squest on new release. Note Read the changelog of the version before performing any update to know what are the breaking changes or specific requirements of the new release. Note We recommend performing a manual backup before any upgrade. See the dedicated backup doc Stop all containers that use the Squest image docker-compose kill django celery-worker celery-beat Starting from here, the maintenance page should appear automatically in place of the Squest app. Pull the new image docker pull quay.io/hewlettpackardenterprise/squest:<version> E.g docker pull quay.io/hewlettpackardenterprise/squest:latest Start back containers docker-compose start django celery-worker celery-beat","title":"Upgrade"},{"location":"administration/upgrade/#squest-upgrade","text":"This documentation aims at explaining how to perform an upgrade of squest on new release. Note Read the changelog of the version before performing any update to know what are the breaking changes or specific requirements of the new release. Note We recommend performing a manual backup before any upgrade. See the dedicated backup doc Stop all containers that use the Squest image docker-compose kill django celery-worker celery-beat Starting from here, the maintenance page should appear automatically in place of the Squest app. Pull the new image docker pull quay.io/hewlettpackardenterprise/squest:<version> E.g docker pull quay.io/hewlettpackardenterprise/squest:latest Start back containers docker-compose start django celery-worker celery-beat","title":"Squest upgrade"},{"location":"configuration/ldap/","text":"LDAP authentication backend Default configuration The configuration is loaded from environment variables file placed in the folder docker/environment_variables . Retrieve environment variables from the Squest configuration settings documentation Advanced configuration LDAP can be activated by setting the environment variable LDAP_ENABLED to True in your configuration: LDAP_ENABLED = True You can overide the given configuration by using the ldap.docker-compose.yml file and mount your custom ldap_config.py . The configuration is based on the Django plugin django-auth-ldap . You can follow the official documentation to know available configuration options. Example of ldap_config.py : import os import ldap from django_auth_ldap.config import LDAPSearch print ( \"LDAP config loaded\" ) # ----------------------- # LDAP auth backend # ----------------------- AUTH_LDAP_SERVER_URI = \"ldaps://ad.example.com:636\" AUTH_LDAP_BIND_DN = \"CN=my_app,OU=Service_Accounts,DC=example,DC=com\" AUTH_LDAP_BIND_PASSWORD = os . environ . get ( 'AUTH_LDAP_BIND_PASSWORD' , None ) AUTH_LDAP_USER_SEARCH = LDAPSearch ( \"OU=Service_Accounts,DC=example,DC=com\" , ldap . SCOPE_SUBTREE , \"(uid= %(user)s )\" ) LDAP_CA_FILE_PATH = \"/usr/local/share/ca-certificates/ldap_ca.crt\" # default path in ldap docker compose file AUTH_LDAP_CONNECTION_OPTIONS = { ldap . OPT_X_TLS_CACERTFILE : LDAP_CA_FILE_PATH , ldap . OPT_X_TLS_REQUIRE_CERT : ldap . OPT_X_TLS_ALLOW , ldap . OPT_X_TLS_NEWCTX : 0 } AUTH_LDAP_USER_ATTR_MAP = { \"first_name\" : \"givenName\" , \"last_name\" : \"sn\" , \"email\" : \"uid\" } Update the ldap.docker-compose.yml file to mount your configuration file and the CA certificate of the LDAP server (if LDAPS is used) in django and celery containers: django : volumes : - ./Squest/ldap_config.py:/app/Squest/ldap_config.py - ./docker/certs/ldap_ca.crt:/usr/local/share/ca-certificates/ldap_ca.crt celery-worker : volumes : - ./Squest/ldap_config.py:/app/Squest/ldap_config.py - ./docker/certs/ldap_ca.crt:/usr/local/share/ca-certificates/ldap_ca.crt celery-beat : volumes : - ./Squest/ldap_config.py:/app/Squest/ldap_config.py - ./docker/certs/ldap_ca.crt:/usr/local/share/ca-certificates/ldap_ca.crt Run docker compose with the ldap config docker-compose -f docker-compose.yml -f docker-compose.override.yml -f ldap.docker-compose.yml up","title":"LDAP"},{"location":"configuration/ldap/#ldap-authentication-backend","text":"","title":"LDAP authentication backend"},{"location":"configuration/ldap/#default-configuration","text":"The configuration is loaded from environment variables file placed in the folder docker/environment_variables . Retrieve environment variables from the Squest configuration settings documentation","title":"Default configuration"},{"location":"configuration/ldap/#advanced-configuration","text":"LDAP can be activated by setting the environment variable LDAP_ENABLED to True in your configuration: LDAP_ENABLED = True You can overide the given configuration by using the ldap.docker-compose.yml file and mount your custom ldap_config.py . The configuration is based on the Django plugin django-auth-ldap . You can follow the official documentation to know available configuration options. Example of ldap_config.py : import os import ldap from django_auth_ldap.config import LDAPSearch print ( \"LDAP config loaded\" ) # ----------------------- # LDAP auth backend # ----------------------- AUTH_LDAP_SERVER_URI = \"ldaps://ad.example.com:636\" AUTH_LDAP_BIND_DN = \"CN=my_app,OU=Service_Accounts,DC=example,DC=com\" AUTH_LDAP_BIND_PASSWORD = os . environ . get ( 'AUTH_LDAP_BIND_PASSWORD' , None ) AUTH_LDAP_USER_SEARCH = LDAPSearch ( \"OU=Service_Accounts,DC=example,DC=com\" , ldap . SCOPE_SUBTREE , \"(uid= %(user)s )\" ) LDAP_CA_FILE_PATH = \"/usr/local/share/ca-certificates/ldap_ca.crt\" # default path in ldap docker compose file AUTH_LDAP_CONNECTION_OPTIONS = { ldap . OPT_X_TLS_CACERTFILE : LDAP_CA_FILE_PATH , ldap . OPT_X_TLS_REQUIRE_CERT : ldap . OPT_X_TLS_ALLOW , ldap . OPT_X_TLS_NEWCTX : 0 } AUTH_LDAP_USER_ATTR_MAP = { \"first_name\" : \"givenName\" , \"last_name\" : \"sn\" , \"email\" : \"uid\" } Update the ldap.docker-compose.yml file to mount your configuration file and the CA certificate of the LDAP server (if LDAPS is used) in django and celery containers: django : volumes : - ./Squest/ldap_config.py:/app/Squest/ldap_config.py - ./docker/certs/ldap_ca.crt:/usr/local/share/ca-certificates/ldap_ca.crt celery-worker : volumes : - ./Squest/ldap_config.py:/app/Squest/ldap_config.py - ./docker/certs/ldap_ca.crt:/usr/local/share/ca-certificates/ldap_ca.crt celery-beat : volumes : - ./Squest/ldap_config.py:/app/Squest/ldap_config.py - ./docker/certs/ldap_ca.crt:/usr/local/share/ca-certificates/ldap_ca.crt Run docker compose with the ldap config docker-compose -f docker-compose.yml -f docker-compose.override.yml -f ldap.docker-compose.yml up","title":"Advanced configuration"},{"location":"configuration/squest_settings/","text":"Configuration settings Default settings are configured to provide a testing/development environment. For a production setup it is recommended to adjust them following your target environment. The configuration is loaded from environment variables file placed in the folder docker/environment_variables . Database DB_ROOT_PASSWORD Set the database root/superuser password DATABASE Default: default Setup mysql database usage Set to psql for postgres SQL usage DB_DATABASE Default: squest_db Database name. DB_USER Default: squest_user User used to connect to the DB_DATABASE name. DB_PASSWORD Default: squest_password Password of the DB_USER username. DB_HOST Default: 127.0.0.1 Database host. The default value is localhost to match the development configuration. Switch to db in production when using the docker-compose based deployment. DB_PORT Default: 3306 Database port. Authentication LDAP LDAP_ENABLED Default: False Set to True to enable LDAP based authentication. AUTH_LDAP_SERVER_URI Default: ldap:port Set the LDAP serveur URI and port AUTH_LDAP_BIND_DN Default: cn=service_account_name,ou=Applications,o=domain.com Set the LDAP DN to authenticate to the LDAP serveur AUTH_LDAP_BIND_PASSWORD Default: NONE Associated to AUTH_LDAP_BIND_DN, password used to authenticate DN AUTH_LDAP_USER_SEARCH Default: ou=People,o=domain.com User search patern AUTH_LDAP_ATTR_FIRSTNAME Default: givenName set the LDAP \"first_name\" attribute AUTH_LDAP_ATTR_LASTNAME Default: sn set the LDAP \"last_name\" attribute AUTH_LDAP_ATTR_MAIL Default: mail set the LDAP \"email\" attribute DEFAULT_ADMIN_TOKEN Default: None Set an API token that will be linked to the admin user when starting Squest. LOGIN_HELPER_TEXT Default: None Add a custom note into the login page that helps user to know what are the expected credentials. HTML text is supported. E.G: \"Use your corporate email and password\". Squest MAINTENANCE_MODE_ENABLED Default: False When enabled, only administrators can access squest UI and API. This can be used for example to block new requests by end users from the service catalog. So an administrator can perform operations against the API like migrating instance specs. Note This can also be set on the fly from the admin panel (top right corner of the UI) in the object Squest settings . SQUEST_HOST Default: http://squest.domain.local Address of the Squest portal instance. Used in email templates and in metadata sent to Red Hat Ansible Automation Platform/AWX job templates. SQUEST_EMAIL_HOST Default: squest@squest.domain.local Domain name used as email sender. E.g: \"squest@squest.domain.local\". SQUEST_EMAIL_NOTIFICATION_ENABLED Default: Based on DEBUG value by default Set to True to enable email notifications. IS_DEV_SERVER Default: False Set to True to change the navbar and footer color to visually identify a testing instance of Squest. SMTP EMAIL_HOST Default: localhost The SMTP host to use for sending email. EMAIL_PORT Default: 25 Port to use for the SMTP server defined in EMAIL_HOST . Backup BACKUP_ENABLED Default: False Switch to True to enable backup. Refer to the dedicated documentation . BACKUP_CRONTAB Default: 0 1 * * * Crontab line for backup. By default, the backup is performed every day at 1AM. DBBACKUP_CLEANUP_KEEP Default: 5 Number of db backup file to keep. Doc . DBBACKUP_CLEANUP_KEEP_MEDIA Default: 5 Number of media backup tar to keep. Doc . Metrics METRICS_ENABLED Default: False Switch to True to enable Prometheus metrics page. METRICS_PASSWORD_PROTECTED Default: True Switch to False to disable the basic authentication on metrics page. METRICS_AUTHORIZATION_USERNAME Default: admin Username for the basic authentication of the metrics page. METRICS_AUTHORIZATION_PASSWORD Default: admin Password for the basic authentication of the metrics page. Auto cleanup DOC_IMAGES_CLEANUP_ENABLED Default: False Switch to True to enable automatic cleanup of ghost docs images from media folder. DOC_IMAGES_CLEANUP_CRONTAB Default: 30 1 * * * Crontab line for ghost image cleanup. By default performed every day at 1:30 AM. Production SECRET_KEY Default: Default randomly-generated Django secret key used for cryptographic signing. Doc . DEBUG Default: True Django DEBUG mode. Switch to False for production. ALLOWED_HOSTS Default: * Comma separated list of allowed FQDN. Refer to the complete documentation . CELERY_BROKER_URL Default: amqp://rabbitmq:rabbitmq@localhost:5672/squest RabbitMQ message broker URL. The default value is localhost to match the development configuration. Replace localhost by rabbitmq in production when using the docker-compose based deployment. CELERY_TASK_SOFT_TIME_LIMIT Default: 300 Async task execution timeout. Doc . LANGUAGE_CODE Default: en-us Django language. Doc TIME_ZONE Default: Europe/Paris Time zone of the server that host Squest service. Doc DATE_FORMAT Default: %d %b, %Y %H:%M Change the format of all date in Squest UI. Based on Python strftime . Plugins FIELD_VALIDATOR_PATH Path to form field validation modules. Default: plugins/field_validators","title":"Squest"},{"location":"configuration/squest_settings/#configuration-settings","text":"Default settings are configured to provide a testing/development environment. For a production setup it is recommended to adjust them following your target environment. The configuration is loaded from environment variables file placed in the folder docker/environment_variables .","title":"Configuration  settings"},{"location":"configuration/squest_settings/#database","text":"","title":"Database"},{"location":"configuration/squest_settings/#db_root_password","text":"Set the database root/superuser password","title":"DB_ROOT_PASSWORD"},{"location":"configuration/squest_settings/#database_1","text":"Default: default Setup mysql database usage Set to psql for postgres SQL usage","title":"DATABASE"},{"location":"configuration/squest_settings/#db_database","text":"Default: squest_db Database name.","title":"DB_DATABASE"},{"location":"configuration/squest_settings/#db_user","text":"Default: squest_user User used to connect to the DB_DATABASE name.","title":"DB_USER"},{"location":"configuration/squest_settings/#db_password","text":"Default: squest_password Password of the DB_USER username.","title":"DB_PASSWORD"},{"location":"configuration/squest_settings/#db_host","text":"Default: 127.0.0.1 Database host. The default value is localhost to match the development configuration. Switch to db in production when using the docker-compose based deployment.","title":"DB_HOST"},{"location":"configuration/squest_settings/#db_port","text":"Default: 3306 Database port.","title":"DB_PORT"},{"location":"configuration/squest_settings/#authentication","text":"","title":"Authentication"},{"location":"configuration/squest_settings/#ldap","text":"","title":"LDAP"},{"location":"configuration/squest_settings/#ldap_enabled","text":"Default: False Set to True to enable LDAP based authentication.","title":"LDAP_ENABLED"},{"location":"configuration/squest_settings/#auth_ldap_server_uri","text":"Default: ldap:port Set the LDAP serveur URI and port","title":"AUTH_LDAP_SERVER_URI"},{"location":"configuration/squest_settings/#auth_ldap_bind_dn","text":"Default: cn=service_account_name,ou=Applications,o=domain.com Set the LDAP DN to authenticate to the LDAP serveur","title":"AUTH_LDAP_BIND_DN"},{"location":"configuration/squest_settings/#auth_ldap_bind_password","text":"Default: NONE Associated to AUTH_LDAP_BIND_DN, password used to authenticate DN","title":"AUTH_LDAP_BIND_PASSWORD"},{"location":"configuration/squest_settings/#auth_ldap_user_search","text":"Default: ou=People,o=domain.com User search patern","title":"AUTH_LDAP_USER_SEARCH"},{"location":"configuration/squest_settings/#auth_ldap_attr_firstname","text":"Default: givenName set the LDAP \"first_name\" attribute","title":"AUTH_LDAP_ATTR_FIRSTNAME"},{"location":"configuration/squest_settings/#auth_ldap_attr_lastname","text":"Default: sn set the LDAP \"last_name\" attribute","title":"AUTH_LDAP_ATTR_LASTNAME"},{"location":"configuration/squest_settings/#auth_ldap_attr_mail","text":"Default: mail set the LDAP \"email\" attribute","title":"AUTH_LDAP_ATTR_MAIL"},{"location":"configuration/squest_settings/#default_admin_token","text":"Default: None Set an API token that will be linked to the admin user when starting Squest.","title":"DEFAULT_ADMIN_TOKEN"},{"location":"configuration/squest_settings/#login_helper_text","text":"Default: None Add a custom note into the login page that helps user to know what are the expected credentials. HTML text is supported. E.G: \"Use your corporate email and password\".","title":"LOGIN_HELPER_TEXT"},{"location":"configuration/squest_settings/#squest","text":"","title":"Squest"},{"location":"configuration/squest_settings/#maintenance_mode_enabled","text":"Default: False When enabled, only administrators can access squest UI and API. This can be used for example to block new requests by end users from the service catalog. So an administrator can perform operations against the API like migrating instance specs. Note This can also be set on the fly from the admin panel (top right corner of the UI) in the object Squest settings .","title":"MAINTENANCE_MODE_ENABLED"},{"location":"configuration/squest_settings/#squest_host","text":"Default: http://squest.domain.local Address of the Squest portal instance. Used in email templates and in metadata sent to Red Hat Ansible Automation Platform/AWX job templates.","title":"SQUEST_HOST"},{"location":"configuration/squest_settings/#squest_email_host","text":"Default: squest@squest.domain.local Domain name used as email sender. E.g: \"squest@squest.domain.local\".","title":"SQUEST_EMAIL_HOST"},{"location":"configuration/squest_settings/#squest_email_notification_enabled","text":"Default: Based on DEBUG value by default Set to True to enable email notifications.","title":"SQUEST_EMAIL_NOTIFICATION_ENABLED"},{"location":"configuration/squest_settings/#is_dev_server","text":"Default: False Set to True to change the navbar and footer color to visually identify a testing instance of Squest.","title":"IS_DEV_SERVER"},{"location":"configuration/squest_settings/#smtp","text":"","title":"SMTP"},{"location":"configuration/squest_settings/#email_host","text":"Default: localhost The SMTP host to use for sending email.","title":"EMAIL_HOST"},{"location":"configuration/squest_settings/#email_port","text":"Default: 25 Port to use for the SMTP server defined in EMAIL_HOST .","title":"EMAIL_PORT"},{"location":"configuration/squest_settings/#backup","text":"","title":"Backup"},{"location":"configuration/squest_settings/#backup_enabled","text":"Default: False Switch to True to enable backup. Refer to the dedicated documentation .","title":"BACKUP_ENABLED"},{"location":"configuration/squest_settings/#backup_crontab","text":"Default: 0 1 * * * Crontab line for backup. By default, the backup is performed every day at 1AM.","title":"BACKUP_CRONTAB"},{"location":"configuration/squest_settings/#dbbackup_cleanup_keep","text":"Default: 5 Number of db backup file to keep. Doc .","title":"DBBACKUP_CLEANUP_KEEP"},{"location":"configuration/squest_settings/#dbbackup_cleanup_keep_media","text":"Default: 5 Number of media backup tar to keep. Doc .","title":"DBBACKUP_CLEANUP_KEEP_MEDIA"},{"location":"configuration/squest_settings/#metrics","text":"","title":"Metrics"},{"location":"configuration/squest_settings/#metrics_enabled","text":"Default: False Switch to True to enable Prometheus metrics page.","title":"METRICS_ENABLED"},{"location":"configuration/squest_settings/#metrics_password_protected","text":"Default: True Switch to False to disable the basic authentication on metrics page.","title":"METRICS_PASSWORD_PROTECTED"},{"location":"configuration/squest_settings/#metrics_authorization_username","text":"Default: admin Username for the basic authentication of the metrics page.","title":"METRICS_AUTHORIZATION_USERNAME"},{"location":"configuration/squest_settings/#metrics_authorization_password","text":"Default: admin Password for the basic authentication of the metrics page.","title":"METRICS_AUTHORIZATION_PASSWORD"},{"location":"configuration/squest_settings/#auto-cleanup","text":"","title":"Auto cleanup"},{"location":"configuration/squest_settings/#doc_images_cleanup_enabled","text":"Default: False Switch to True to enable automatic cleanup of ghost docs images from media folder.","title":"DOC_IMAGES_CLEANUP_ENABLED"},{"location":"configuration/squest_settings/#doc_images_cleanup_crontab","text":"Default: 30 1 * * * Crontab line for ghost image cleanup. By default performed every day at 1:30 AM.","title":"DOC_IMAGES_CLEANUP_CRONTAB"},{"location":"configuration/squest_settings/#production","text":"","title":"Production"},{"location":"configuration/squest_settings/#secret_key","text":"Default: Default randomly-generated Django secret key used for cryptographic signing. Doc .","title":"SECRET_KEY"},{"location":"configuration/squest_settings/#debug","text":"Default: True Django DEBUG mode. Switch to False for production.","title":"DEBUG"},{"location":"configuration/squest_settings/#allowed_hosts","text":"Default: * Comma separated list of allowed FQDN. Refer to the complete documentation .","title":"ALLOWED_HOSTS"},{"location":"configuration/squest_settings/#celery_broker_url","text":"Default: amqp://rabbitmq:rabbitmq@localhost:5672/squest RabbitMQ message broker URL. The default value is localhost to match the development configuration. Replace localhost by rabbitmq in production when using the docker-compose based deployment.","title":"CELERY_BROKER_URL"},{"location":"configuration/squest_settings/#celery_task_soft_time_limit","text":"Default: 300 Async task execution timeout. Doc .","title":"CELERY_TASK_SOFT_TIME_LIMIT"},{"location":"configuration/squest_settings/#language_code","text":"Default: en-us Django language. Doc","title":"LANGUAGE_CODE"},{"location":"configuration/squest_settings/#time_zone","text":"Default: Europe/Paris Time zone of the server that host Squest service. Doc","title":"TIME_ZONE"},{"location":"configuration/squest_settings/#date_format","text":"Default: %d %b, %Y %H:%M Change the format of all date in Squest UI. Based on Python strftime .","title":"DATE_FORMAT"},{"location":"configuration/squest_settings/#plugins","text":"","title":"Plugins"},{"location":"configuration/squest_settings/#field_validator_path","text":"Path to form field validation modules. Default: plugins/field_validators","title":"FIELD_VALIDATOR_PATH"},{"location":"configuration/tls/","text":"TLS This section explains how to add TLS support on Squest. The TLS endpoint is managed by a reverse proxy on top of the default web server. This is not the only way to handle this part. Many tools like Nginx, Apache or Traefik could be used, and you are free to use the one you want instead of this proposed configuration. The only recommendation we have is to keep the default nginx web server as main http entrypoint. TLS using Caddy Caddy is a powerful webserver written in Go which provide a reverse proxy feature. In the example below, we'll use self-signed certificate. Follow the official documentation if you want to configure it to use an ACME like \"Let's Encrypt\" instead. Place your certificate and key file in the folder docker/certs . E.g: docker \u251c\u2500\u2500 Caddyfile \u251c\u2500\u2500 certs \u2502 \u251c\u2500\u2500 squest.crt \u2502 \u2514\u2500\u2500 squest.key Update the docker/Caddyfile with the FQDN of your server. By default, the FQDN is set to squest.domain.local squest.domain.local { # This line should match the ALLOWED_HOSTS in your Squest environment reverse_proxy nginx:8080 encode gzip zstd tls /etc/ssl/private/squest.crt /etc/ssl/private/squest.key # or: # tls /etc/ssl/private/cert.pem log { level error } } Update the ALLOWED_HOSTS environment variable from the configuration file docker/environment_variables/squest.env to match your FQDN. ALLOWED_HOSTS = squest.domain.local Start docker compose with the TLS configuration: docker-compose -f docker-compose.yml -f tls.docker-compose.yml up The squest service is then reachable via HTTP and HTTPS standard ports (80/443). http://squest.domain.local https://squest.domain.local","title":"TLS"},{"location":"configuration/tls/#tls","text":"This section explains how to add TLS support on Squest. The TLS endpoint is managed by a reverse proxy on top of the default web server. This is not the only way to handle this part. Many tools like Nginx, Apache or Traefik could be used, and you are free to use the one you want instead of this proposed configuration. The only recommendation we have is to keep the default nginx web server as main http entrypoint.","title":"TLS"},{"location":"configuration/tls/#tls-using-caddy","text":"Caddy is a powerful webserver written in Go which provide a reverse proxy feature. In the example below, we'll use self-signed certificate. Follow the official documentation if you want to configure it to use an ACME like \"Let's Encrypt\" instead. Place your certificate and key file in the folder docker/certs . E.g: docker \u251c\u2500\u2500 Caddyfile \u251c\u2500\u2500 certs \u2502 \u251c\u2500\u2500 squest.crt \u2502 \u2514\u2500\u2500 squest.key Update the docker/Caddyfile with the FQDN of your server. By default, the FQDN is set to squest.domain.local squest.domain.local { # This line should match the ALLOWED_HOSTS in your Squest environment reverse_proxy nginx:8080 encode gzip zstd tls /etc/ssl/private/squest.crt /etc/ssl/private/squest.key # or: # tls /etc/ssl/private/cert.pem log { level error } } Update the ALLOWED_HOSTS environment variable from the configuration file docker/environment_variables/squest.env to match your FQDN. ALLOWED_HOSTS = squest.domain.local Start docker compose with the TLS configuration: docker-compose -f docker-compose.yml -f tls.docker-compose.yml up The squest service is then reachable via HTTP and HTTPS standard ports (80/443). http://squest.domain.local https://squest.domain.local","title":"TLS using Caddy"},{"location":"contribute/code/","text":"Contributing: code The community can contribute to Squest by providing some new features, bug fix and enhancements. How to contribute Fork it! Checkout the dev branch git checkout dev Create your feature branch: git checkout -b my-new-feature Commit your changes: git commit -am 'Add some feature' Push to the branch: git push origin my-new-feature Submit a pull request in the dev branch If you are new on Github environment, we recommend you to read the first contribution guide . Follow the development environment setup documentation to prepare your workstation with prerequisites. Constraints Respect PEP 257 -- Docstring conventions. For each class or method add a description with summary, input parameter, returned parameter, type of parameter def my_method ( my_parameter ): \"\"\" Description of he method :param my_parameter: description of he parameter :type my_parameter: str \"\"\" pass Respect PEP 8 -- Style Guide for Python Code We recommend the usage of an IDE like Pycharm","title":"Code"},{"location":"contribute/code/#contributing-code","text":"The community can contribute to Squest by providing some new features, bug fix and enhancements. How to contribute Fork it! Checkout the dev branch git checkout dev Create your feature branch: git checkout -b my-new-feature Commit your changes: git commit -am 'Add some feature' Push to the branch: git push origin my-new-feature Submit a pull request in the dev branch If you are new on Github environment, we recommend you to read the first contribution guide . Follow the development environment setup documentation to prepare your workstation with prerequisites.","title":"Contributing: code"},{"location":"contribute/code/#constraints","text":"Respect PEP 257 -- Docstring conventions. For each class or method add a description with summary, input parameter, returned parameter, type of parameter def my_method ( my_parameter ): \"\"\" Description of he method :param my_parameter: description of he parameter :type my_parameter: str \"\"\" pass Respect PEP 8 -- Style Guide for Python Code We recommend the usage of an IDE like Pycharm","title":"Constraints"},{"location":"contribute/documentation/","text":"Contributing to the documentation The documentation is written in markdown and then generated with mkdocs . Required libraries are installed if you've followed the development environment documentation of the project. Graphs and diagrams are generated by the Mermaid library . Update the documentation in the docs folder placed in the root of the project. Run dev server locally to check the result mkdocs serve -a 0 .0.0.0:4000 The page is available on http://127.0.0.1:4000 . Send a pull request then to propose your changes to the project. Notes Reset your gh-pages branch to match the upstream If you've built mkdocs and published a version in your fork for testing, your gh-pages branch will differ from the upstream repository. To reset your local gh-pages , follow the procedure below: # delete local branch git branch -D gh-pages # delete remote branch (fork here is your remote. Replace by origin if needed) git push -d fork gh-pages # checkout gh-pages git checkout --orphan gh-pages # pull last version (upstream is the remote name of the main repo) git pull upstream gh-pages # (optional) force push to your fork to override changes git push -f fork gh-pages # go back to your original branch git checkout master","title":"Documentation"},{"location":"contribute/documentation/#contributing-to-the-documentation","text":"The documentation is written in markdown and then generated with mkdocs . Required libraries are installed if you've followed the development environment documentation of the project. Graphs and diagrams are generated by the Mermaid library . Update the documentation in the docs folder placed in the root of the project. Run dev server locally to check the result mkdocs serve -a 0 .0.0.0:4000 The page is available on http://127.0.0.1:4000 . Send a pull request then to propose your changes to the project.","title":"Contributing to the documentation"},{"location":"contribute/documentation/#notes","text":"","title":"Notes"},{"location":"contribute/documentation/#reset-your-gh-pages-branch-to-match-the-upstream","text":"If you've built mkdocs and published a version in your fork for testing, your gh-pages branch will differ from the upstream repository. To reset your local gh-pages , follow the procedure below: # delete local branch git branch -D gh-pages # delete remote branch (fork here is your remote. Replace by origin if needed) git push -d fork gh-pages # checkout gh-pages git checkout --orphan gh-pages # pull last version (upstream is the remote name of the main repo) git pull upstream gh-pages # (optional) force push to your fork to override changes git push -f fork gh-pages # go back to your original branch git checkout master","title":"Reset your gh-pages branch to match the upstream"},{"location":"dev/dev-env/","text":"Setup a development environment Pre requisites Tools Following tools need to be installed on your workstation: Docker Docker-compose Python 3.9 Python virtualenv Poetry npm 8 System packages Ubuntu based OS: sudo apt-get install libmysqlclient-dev graphviz default-mysql-client libsqlite3-dev libsasl2-dev python3-dev libldap2-dev libssl-dev libpq-dev CentOS/RedHat/Fedora sudo yum install mysql-devel graphviz mysql libsq3-devel libpq-devel Start a development environment The development environment is composed of 4 parts: Docker compose: The Docker compose file is used to deploy all required components such as the database and the message broker Celery worker: The Celery worker is a separated process that receive tasks from the main Django process to be executed asynchronously Celery beat: Celery beat is a periodic task scheduler that send task into the celery worker based on a frequency. This part is used by Squest to check the status of executed RHAAP/AWX job Django built in web server: Integrated web server used only for development purpose. main process of the application that serve the Web Ui and the API Docker compose Run the Docker compose file with only required services to bring up database, message broker and other required system docker-compose -f docker-compose.yml -f dev.docker-compose.yml up db phpmyadmin rabbitmq redis-cache If you use postgreSQL, update docker/environment_variables/squest.env, then run docker-compose -f docker-compose.yml -f psql.docker-composer.yml -f dev.docker-compose.yml up db phpmyadmin rabbitmq redis-cache Javascript libraries Install JS libs (npm need to be installed) npm install Python environment Initializing and installing python libraries with Poetry poetry install Go into the python virtual env poetry shell Create the database with Django migration script python manage.py migrate Collect static files python manage.py collectstatic --noinput Insert default data python manage.py insert_default_data Celery worker and periodic task scheduler Run Celery process for async tasks from a new terminal poetry shell celery -A service_catalog worker -l info Run Celery beat for periodic tasks from a new terminal poetry shell celery -A service_catalog worker --beat -l info Django integrated web server This next command should be executed from your IDE. Run django dev server poetry shell python manage.py runserver Settings are placed into the squest/settings.py file which is a standard Django core settings file . Commands To clean all Celery pending tasks poetry shell celery -A restapi purge Execute tests Run unit tests poetry shell python manage.py test Run code coverage coverage run --source = '.' manage.py test # generate terminal report coverage report # generate HTML report coverage html phpMyAdmin phpMyAdmin is exposed on localhost:8082. server : db user : root password : p@ssw0rd","title":"Setup a dev env"},{"location":"dev/dev-env/#setup-a-development-environment","text":"","title":"Setup a development environment"},{"location":"dev/dev-env/#pre-requisites","text":"","title":"Pre requisites"},{"location":"dev/dev-env/#tools","text":"Following tools need to be installed on your workstation: Docker Docker-compose Python 3.9 Python virtualenv Poetry npm 8","title":"Tools"},{"location":"dev/dev-env/#system-packages","text":"Ubuntu based OS: sudo apt-get install libmysqlclient-dev graphviz default-mysql-client libsqlite3-dev libsasl2-dev python3-dev libldap2-dev libssl-dev libpq-dev CentOS/RedHat/Fedora sudo yum install mysql-devel graphviz mysql libsq3-devel libpq-devel","title":"System packages"},{"location":"dev/dev-env/#start-a-development-environment","text":"The development environment is composed of 4 parts: Docker compose: The Docker compose file is used to deploy all required components such as the database and the message broker Celery worker: The Celery worker is a separated process that receive tasks from the main Django process to be executed asynchronously Celery beat: Celery beat is a periodic task scheduler that send task into the celery worker based on a frequency. This part is used by Squest to check the status of executed RHAAP/AWX job Django built in web server: Integrated web server used only for development purpose. main process of the application that serve the Web Ui and the API","title":"Start a development environment"},{"location":"dev/dev-env/#docker-compose","text":"Run the Docker compose file with only required services to bring up database, message broker and other required system docker-compose -f docker-compose.yml -f dev.docker-compose.yml up db phpmyadmin rabbitmq redis-cache If you use postgreSQL, update docker/environment_variables/squest.env, then run docker-compose -f docker-compose.yml -f psql.docker-composer.yml -f dev.docker-compose.yml up db phpmyadmin rabbitmq redis-cache","title":"Docker compose"},{"location":"dev/dev-env/#javascript-libraries","text":"Install JS libs (npm need to be installed) npm install","title":"Javascript libraries"},{"location":"dev/dev-env/#python-environment","text":"Initializing and installing python libraries with Poetry poetry install Go into the python virtual env poetry shell Create the database with Django migration script python manage.py migrate Collect static files python manage.py collectstatic --noinput Insert default data python manage.py insert_default_data","title":"Python environment"},{"location":"dev/dev-env/#celery-worker-and-periodic-task-scheduler","text":"Run Celery process for async tasks from a new terminal poetry shell celery -A service_catalog worker -l info Run Celery beat for periodic tasks from a new terminal poetry shell celery -A service_catalog worker --beat -l info","title":"Celery worker and periodic task scheduler"},{"location":"dev/dev-env/#django-integrated-web-server","text":"This next command should be executed from your IDE. Run django dev server poetry shell python manage.py runserver Settings are placed into the squest/settings.py file which is a standard Django core settings file .","title":"Django integrated web server"},{"location":"dev/dev-env/#commands","text":"To clean all Celery pending tasks poetry shell celery -A restapi purge","title":"Commands"},{"location":"dev/dev-env/#execute-tests","text":"Run unit tests poetry shell python manage.py test Run code coverage coverage run --source = '.' manage.py test # generate terminal report coverage report # generate HTML report coverage html","title":"Execute tests"},{"location":"dev/dev-env/#phpmyadmin","text":"phpMyAdmin is exposed on localhost:8082. server : db user : root password : p@ssw0rd","title":"phpMyAdmin"},{"location":"dev/instance-state-machine/","text":"Instance state machine graph TB start((Start)) start --> pending pending[PENDING] provisioning[PROVISIONING] provision_failed[PROVISION_FAILED] available[AVAILABLE] updating[UPDATING] update_failed[UPDATE_FAILED] deleting[DELETING] delete_failed[DELETE_FAILED] deleted[DELETED] archived[ARCHIVED] pending --> provisioning provision_ok{provision ok?} style provision_ok fill:#80CBC4 provisioning --> provision_ok provision_ok --> |No| provision_failed provision_ok --> |Yes| available provision_failed --> |retry| provisioning available --> |update| updating update_ok{update ok?} style update_ok fill:#80CBC4 updating --> update_ok update_ok --> |No| update_failed update_ok --> |Yes| available available --> |Delete| deleting deletion_ok{deletion ok?} style deletion_ok fill:#80CBC4 deleting --> deletion_ok deletion_ok --> |No| delete_failed deletion_ok --> |Yes| deleted deleted --> |archive| archived delete_failed --> |Retry| deleting","title":"Instance state machine"},{"location":"dev/instance-state-machine/#instance-state-machine","text":"graph TB start((Start)) start --> pending pending[PENDING] provisioning[PROVISIONING] provision_failed[PROVISION_FAILED] available[AVAILABLE] updating[UPDATING] update_failed[UPDATE_FAILED] deleting[DELETING] delete_failed[DELETE_FAILED] deleted[DELETED] archived[ARCHIVED] pending --> provisioning provision_ok{provision ok?} style provision_ok fill:#80CBC4 provisioning --> provision_ok provision_ok --> |No| provision_failed provision_ok --> |Yes| available provision_failed --> |retry| provisioning available --> |update| updating update_ok{update ok?} style update_ok fill:#80CBC4 updating --> update_ok update_ok --> |No| update_failed update_ok --> |Yes| available available --> |Delete| deleting deletion_ok{deletion ok?} style deletion_ok fill:#80CBC4 deleting --> deletion_ok deletion_ok --> |No| delete_failed deletion_ok --> |Yes| deleted deleted --> |archive| archived delete_failed --> |Retry| deleting","title":"Instance state machine"},{"location":"dev/release/","text":"Release new version of Squest Prepare Create a release branch Update the CHANGELOG.md Delete all migration file since the last release in all Django app Make migration files Update Squest/version.py with release version Update version in Poetry pyproject.toml PR --> master Last review and rebase/merge master CI execution From here the CI will: Build the new docker image Push the image in quay.io Build and publish the mkdocs documentation into GitHub pages Post CI Tag the branch with the new version and push the tag Create a release from the pushed tag on GitHub Create new dev branch Update version.py with new beta version Update poetry version in pyproject.toml with new beta version (E.g: 1.8.3b ) Bump poetry libraries Force push the new dev branch to upstream Notify community in Gitter","title":"Release"},{"location":"dev/release/#release-new-version-of-squest","text":"","title":"Release new version of Squest"},{"location":"dev/release/#prepare","text":"Create a release branch Update the CHANGELOG.md Delete all migration file since the last release in all Django app Make migration files Update Squest/version.py with release version Update version in Poetry pyproject.toml PR --> master Last review and rebase/merge master","title":"Prepare"},{"location":"dev/release/#ci-execution","text":"From here the CI will: Build the new docker image Push the image in quay.io Build and publish the mkdocs documentation into GitHub pages","title":"CI execution"},{"location":"dev/release/#post-ci","text":"Tag the branch with the new version and push the tag Create a release from the pushed tag on GitHub Create new dev branch Update version.py with new beta version Update poetry version in pyproject.toml with new beta version (E.g: 1.8.3b ) Bump poetry libraries Force push the new dev branch to upstream Notify community in Gitter","title":"Post CI"},{"location":"dev/request-state-machine/","text":"Request state machine graph TB start((Start)) submitted[SUBMITTED] start --> submitted auto_accept{auto accept?} style auto_accept fill:#80CBC4 instance_pending([instance pending]) submitted --> instance_pending instance_pending --> auto_accept accepted[ACCEPTED] auto_accept -->|Yes| accepted admin_action_1{admin action} style admin_action_1 fill:#80DEEA auto_accept -->|No| admin_action_1 need_info[NEED_INFO] admin_action_1 -->|need_info| need_info admin_action_1 -->|accept| accepted rejected[REJECTED] need_info -->|reject| rejected need_info -->|Submit| submitted canceled[CANCELED] need_info --> |cancel|canceled rejected --> |cancel|canceled submitted --> |cancel|canceled submitted -->|reject| rejected canceled --> |delete| deleted deleted((Deleted)) auto_pocess{auto process?} style auto_pocess fill:#80CBC4 accepted --> auto_pocess accepted -->|reject| rejected auto_pocess --> |Yes| operation_type admin_action_2{admin action} auto_pocess --> |No| admin_action_2 admin_action_2 --> |process| operation_type style admin_action_2 fill:#80DEEA operation_type{Operation type?} style operation_type fill:#80CBC4 instance_creating([instance_creating]) instance_updating([instance_updating]) instance_deleting([instance_deleting]) operation_type --> |CREATE| instance_creating operation_type --> |UPDATE| instance_updating operation_type --> |DELETE| instance_deleting processing[PROCESSING] instance_creating --> processing instance_updating --> processing instance_deleting --> processing processing_ok{processing ok?} style processing_ok fill:#80CBC4 processing --> processing_ok complete[COMPLETE] failed[FAILED] processing_ok --> |Yes| complete processing_ok --> |No| failed failed --> |retry| processing failed --> |cancel| accepted archived[ARCHIVED] complete -->|archive| archived archived -->|unarchive| complete","title":"Request state machine"},{"location":"dev/request-state-machine/#request-state-machine","text":"graph TB start((Start)) submitted[SUBMITTED] start --> submitted auto_accept{auto accept?} style auto_accept fill:#80CBC4 instance_pending([instance pending]) submitted --> instance_pending instance_pending --> auto_accept accepted[ACCEPTED] auto_accept -->|Yes| accepted admin_action_1{admin action} style admin_action_1 fill:#80DEEA auto_accept -->|No| admin_action_1 need_info[NEED_INFO] admin_action_1 -->|need_info| need_info admin_action_1 -->|accept| accepted rejected[REJECTED] need_info -->|reject| rejected need_info -->|Submit| submitted canceled[CANCELED] need_info --> |cancel|canceled rejected --> |cancel|canceled submitted --> |cancel|canceled submitted -->|reject| rejected canceled --> |delete| deleted deleted((Deleted)) auto_pocess{auto process?} style auto_pocess fill:#80CBC4 accepted --> auto_pocess accepted -->|reject| rejected auto_pocess --> |Yes| operation_type admin_action_2{admin action} auto_pocess --> |No| admin_action_2 admin_action_2 --> |process| operation_type style admin_action_2 fill:#80DEEA operation_type{Operation type?} style operation_type fill:#80CBC4 instance_creating([instance_creating]) instance_updating([instance_updating]) instance_deleting([instance_deleting]) operation_type --> |CREATE| instance_creating operation_type --> |UPDATE| instance_updating operation_type --> |DELETE| instance_deleting processing[PROCESSING] instance_creating --> processing instance_updating --> processing instance_deleting --> processing processing_ok{processing ok?} style processing_ok fill:#80CBC4 processing --> processing_ok complete[COMPLETE] failed[FAILED] processing_ok --> |Yes| complete processing_ok --> |No| failed failed --> |retry| processing failed --> |cancel| accepted archived[ARCHIVED] complete -->|archive| archived archived -->|unarchive| complete","title":"Request state machine"},{"location":"manual/access/","text":"Access Squest accesses are managed by following levels: flowchart TD Global --> Organizations --> Teams --> Users Organizations --> Users Global scopes Global scopes are permissions that are set to a particular user on the \"Global\" level. A permission set as this level is granted across all organizations and teams. Organizations and Teams Organization is a scope that may contain Teams and Users. Teams are group of user that belong to an Organization. Note A user need to be present into an organization in order to be added to a team Default roles When creating an organization or a team, default roles can be assigned. Those roles are automatically granted to each user added then to the Organization/Team. For example, setting \"Instance Viewer\" as default role will allow every member of the Organization to see all created instance from the service catalog. RBAC RBAC (Role Based Access Control) allows to set some roles to users of an organization or a team. Quota When an attribute is defined in the resource tracker it becomes automatically available as a quota in organizations or teams. When a request is made with a survey field attached to a quota , then the value is limited to the current quota available. Once the request is accepted, the created resource is linked to the service catalog instance and the available quota limit is updated. Warning The quota depend on created resources in the resource tracking. In order to use a quota, each instance of the service catalog need to be linked to a resource of the resource tracking. Example here . Quota can be set at organization or team level. Each organization can dispatch the given quota to their teams Quotas can be reorganized at anytime across the teams as long as no instance are using them","title":"Access"},{"location":"manual/access/#access","text":"Squest accesses are managed by following levels: flowchart TD Global --> Organizations --> Teams --> Users Organizations --> Users","title":"Access"},{"location":"manual/access/#global-scopes","text":"Global scopes are permissions that are set to a particular user on the \"Global\" level. A permission set as this level is granted across all organizations and teams.","title":"Global scopes"},{"location":"manual/access/#organizations-and-teams","text":"Organization is a scope that may contain Teams and Users. Teams are group of user that belong to an Organization. Note A user need to be present into an organization in order to be added to a team","title":"Organizations and Teams"},{"location":"manual/access/#default-roles","text":"When creating an organization or a team, default roles can be assigned. Those roles are automatically granted to each user added then to the Organization/Team. For example, setting \"Instance Viewer\" as default role will allow every member of the Organization to see all created instance from the service catalog.","title":"Default roles"},{"location":"manual/access/#rbac","text":"RBAC (Role Based Access Control) allows to set some roles to users of an organization or a team.","title":"RBAC"},{"location":"manual/access/#quota","text":"When an attribute is defined in the resource tracker it becomes automatically available as a quota in organizations or teams. When a request is made with a survey field attached to a quota , then the value is limited to the current quota available. Once the request is accepted, the created resource is linked to the service catalog instance and the available quota limit is updated. Warning The quota depend on created resources in the resource tracking. In order to use a quota, each instance of the service catalog need to be linked to a resource of the resource tracking. Example here . Quota can be set at organization or team level. Each organization can dispatch the given quota to their teams Quotas can be reorganized at anytime across the teams as long as no instance are using them","title":"Quota"},{"location":"manual/notifications/","text":"Notifications Note Squest current notification system only support emails. Enable or disable notifications By default, notifications are enabled. You can disable all notifications from your profile page by accessing the profile page in the top right corner of the Squest application. Notification filters Notifications are sent by default for all events. Filters can be added to limit notifications to some criteria: Services Operations Request states Instance states On instance spec conditions (when) When a filter is declared, all criteria in the filter must be valid to send a notification. For example, if a service and an operation is defined both need to be valid. Example behavior with 2 criteria defined: service1 AND operation2 When multiple item are selected for a particular criteria, only one item need to match to validate the criteria. Example behavior when setting multiple service and multiple operation: (service1 OR service2) AND (operation2 OR operation2) When: Ansible like conditions The when condition allows to filter notification based on current \"request\". The syntax is the same as the one used in Ansible. The request object is directly usable as context in the condition without JINJA double-curly braces. See the Jinja documentation for more example. E.g with a 'when' based on the survey filled by the user request . fill_in_survey [ 'location' ] == 'grenoble' E.g with instance spec request . instance . spec [ 'spec_key1' ] == 'spec_value1'","title":"Notifications"},{"location":"manual/notifications/#notifications","text":"Note Squest current notification system only support emails.","title":"Notifications"},{"location":"manual/notifications/#enable-or-disable-notifications","text":"By default, notifications are enabled. You can disable all notifications from your profile page by accessing the profile page in the top right corner of the Squest application.","title":"Enable or disable notifications"},{"location":"manual/notifications/#notification-filters","text":"Notifications are sent by default for all events. Filters can be added to limit notifications to some criteria: Services Operations Request states Instance states On instance spec conditions (when) When a filter is declared, all criteria in the filter must be valid to send a notification. For example, if a service and an operation is defined both need to be valid. Example behavior with 2 criteria defined: service1 AND operation2 When multiple item are selected for a particular criteria, only one item need to match to validate the criteria. Example behavior when setting multiple service and multiple operation: (service1 OR service2) AND (operation2 OR operation2)","title":"Notification filters"},{"location":"manual/notifications/#when-ansible-like-conditions","text":"The when condition allows to filter notification based on current \"request\". The syntax is the same as the one used in Ansible. The request object is directly usable as context in the condition without JINJA double-curly braces. See the Jinja documentation for more example. E.g with a 'when' based on the survey filled by the user request . fill_in_survey [ 'location' ] == 'grenoble' E.g with instance spec request . instance . spec [ 'spec_key1' ] == 'spec_value1'","title":"When: Ansible like conditions"},{"location":"manual/administration/approval_workflow/","text":"Approval workflows By default, Requests can be approved by any user which has the accept_request permission. Approval workflows are a way to split the request accepting process in multiple step that can be reviewed by any user with a custom permission . Approval workflow can be scoped to some organization or team so a same operation can be requested differently following who is asking it. Each step may have a part of the required operation's survey. Workflows An Approval Workflow is composed by one or multiple Approval Step . Approval Steps of the Workflow must be approved one by one following the order. After accepting the last one, the request switch to ACCEPTED state and can be processed. Note The auto-accept option can not be set in the Operation with an Approval Workflow. This need to be configured into the step auto accept condition Configuration: Name Description Name Unique identifier of the Approval Workflow Operation Service operation that will use the workflow Restricted scopes List of organization or team which are going to be concerned by the workflow Steps Steps are the breakpoint of a Squest request. Each step need to be accepted in order to validate the request. Configuration: Name Description Name Unique identifier of the Step Permission Permission required to be allowed to accept or reject the request. By default set to approve_reject_approvalstep Readable field Field from the survey that will be shown in the form but cannot be updated in the step Editable field Field from the survey that can be filled or updated from a previous step Auto accept condition An Ansible \"when\" like that enable auto accept on a Step (see below) Warning If the job template behind the operation has some mandatory fields in its survey then those fields need to be configured in at least in one step. By default, Squest comes with a single permission named approve_reject_approvalstep that can be used in steps. Custom permissions can be created and added to a role to avoid using the default one. flowchart LR role --> permission step --> permission user/team/organization --> role Auto accept A step can be auto accepted on a condition placed in the \"Auto accept condition\" of the step configuration. The condition is a Jinja string which is evaluated like an Ansible when condition. The available context is the request . For example, to validate the step following the name of the instance: request.instance.name == 'this_is_a_very_good_name' Or testing a survey field request.fill_in_survey['vCPU'] < 8 Full request object definition can be retrieved through the API documentation . More example of jinja templating are available in the dedicated documentation section . Warning The auto accept process will not complete or update the survey. If a mandatory field is missing at the end of the approval, the executed job template may fail due to missing variable.","title":"Approval workflow"},{"location":"manual/administration/approval_workflow/#approval-workflows","text":"By default, Requests can be approved by any user which has the accept_request permission. Approval workflows are a way to split the request accepting process in multiple step that can be reviewed by any user with a custom permission . Approval workflow can be scoped to some organization or team so a same operation can be requested differently following who is asking it. Each step may have a part of the required operation's survey.","title":"Approval workflows"},{"location":"manual/administration/approval_workflow/#workflows","text":"An Approval Workflow is composed by one or multiple Approval Step . Approval Steps of the Workflow must be approved one by one following the order. After accepting the last one, the request switch to ACCEPTED state and can be processed. Note The auto-accept option can not be set in the Operation with an Approval Workflow. This need to be configured into the step auto accept condition Configuration: Name Description Name Unique identifier of the Approval Workflow Operation Service operation that will use the workflow Restricted scopes List of organization or team which are going to be concerned by the workflow","title":"Workflows"},{"location":"manual/administration/approval_workflow/#steps","text":"Steps are the breakpoint of a Squest request. Each step need to be accepted in order to validate the request. Configuration: Name Description Name Unique identifier of the Step Permission Permission required to be allowed to accept or reject the request. By default set to approve_reject_approvalstep Readable field Field from the survey that will be shown in the form but cannot be updated in the step Editable field Field from the survey that can be filled or updated from a previous step Auto accept condition An Ansible \"when\" like that enable auto accept on a Step (see below) Warning If the job template behind the operation has some mandatory fields in its survey then those fields need to be configured in at least in one step. By default, Squest comes with a single permission named approve_reject_approvalstep that can be used in steps. Custom permissions can be created and added to a role to avoid using the default one. flowchart LR role --> permission step --> permission user/team/organization --> role","title":"Steps"},{"location":"manual/administration/approval_workflow/#auto-accept","text":"A step can be auto accepted on a condition placed in the \"Auto accept condition\" of the step configuration. The condition is a Jinja string which is evaluated like an Ansible when condition. The available context is the request . For example, to validate the step following the name of the instance: request.instance.name == 'this_is_a_very_good_name' Or testing a survey field request.fill_in_survey['vCPU'] < 8 Full request object definition can be retrieved through the API documentation . More example of jinja templating are available in the dedicated documentation section . Warning The auto accept process will not complete or update the survey. If a mandatory field is missing at the end of the approval, the executed job template may fail due to missing variable.","title":"Auto accept"},{"location":"manual/administration/extras/","text":"Extras Instance/Request Hooks Instance/Requests hooks are a way to call a RHAAP/AWX job template following the new state of a Request or an Instance . For example, if you want to call a job template that performs an action everytime a Request switch to FAILED state. Create a RequestHook: name: Name of your hook State: The hook will be triggered when an instance of the select model type will switch to this selected state Job template: The RHAAP/AWX job template to execute when an instance of the selected model reach the selected state Extra vars: extra variable as JSON to add to the selected job template States documentation: Available states for a Request . Available states for a Instance . Announcements Announcements allow Squest administrator to notify users. Announcements are displayed to end users in the main Squest page. Administrator defines beginning, end, title, message and type of announcement. Note Configure your time zone . Custom links Custom links allow to display hyperlinks to external content by using Squest instance attributes. Custom links appear as buttons in the top right corner of an instance detail page . Jinja template can be used to insert data from the current squest instance details like instance.spec . For example a link can be created to expose the Hypervisor URL that has been placed into the instance spec of a created resource. Name Required Comment name true Name of the custom link. When loop is used, the name is used for the dropdown button name services true Define in which instance details page the button will appear text true Text in the button. Jinja template supported url true URL of the link. Jinja template supported button color false Color of the displayed button when false Ansible like \"when\" condition loop false Ansible like \"loop\" Enabled false Enable or disable the button Is admin only false When set to true , only Squest administrators can see the button Jinja templating Jinja templating can be used in the text or URL definition. The instance object of the current instance detail page is used as context. Full instance object definition can be retrieved through the API documentation . Instance spec example: { \"key1\" : \"value1\" } Button text example: Button {{ instance.name }} Button url example: https://external_resource.domain/?name={{ instance.spec.key1 }} Rendered button with an instance named \"k8S ns test\": < a href = \"https://external_resource.domain/?name=value1\" > Button k8S ns test </ a > When condition The when condition allow to display the button only on certain condition like the \"when\" flag on Ansible. E.g: spec['configvar'] == 'value' and user_spec['other'] == 'value' Note Like for Ansible, double curly braces are not used in 'when' declaration. Loop When the loop definition is set, a dropdown button is created with a link for each element of the given list. Like for Ansible, the element is exposed as item in the Jinja template of the button text or URL. Instance spec example: { \"my_list\" : [ \"item1\" , \"item2\" ] } Loop example: {{ instance.spec.my_list }} Button text example: name: {{ item }} Button url example: https://external_resource.domain/{{ item }} Rendered links into the dropdown button: < a href = \"https://external_resource.domain/item1\" > name: item1 </ a > < a href = \"https://external_resource.domain/item2\" > name: item2 </ a >","title":"Extras"},{"location":"manual/administration/extras/#extras","text":"","title":"Extras"},{"location":"manual/administration/extras/#instancerequest-hooks","text":"Instance/Requests hooks are a way to call a RHAAP/AWX job template following the new state of a Request or an Instance . For example, if you want to call a job template that performs an action everytime a Request switch to FAILED state. Create a RequestHook: name: Name of your hook State: The hook will be triggered when an instance of the select model type will switch to this selected state Job template: The RHAAP/AWX job template to execute when an instance of the selected model reach the selected state Extra vars: extra variable as JSON to add to the selected job template States documentation: Available states for a Request . Available states for a Instance .","title":"Instance/Request Hooks"},{"location":"manual/administration/extras/#announcements","text":"Announcements allow Squest administrator to notify users. Announcements are displayed to end users in the main Squest page. Administrator defines beginning, end, title, message and type of announcement. Note Configure your time zone .","title":"Announcements"},{"location":"manual/administration/extras/#custom-links","text":"Custom links allow to display hyperlinks to external content by using Squest instance attributes. Custom links appear as buttons in the top right corner of an instance detail page . Jinja template can be used to insert data from the current squest instance details like instance.spec . For example a link can be created to expose the Hypervisor URL that has been placed into the instance spec of a created resource. Name Required Comment name true Name of the custom link. When loop is used, the name is used for the dropdown button name services true Define in which instance details page the button will appear text true Text in the button. Jinja template supported url true URL of the link. Jinja template supported button color false Color of the displayed button when false Ansible like \"when\" condition loop false Ansible like \"loop\" Enabled false Enable or disable the button Is admin only false When set to true , only Squest administrators can see the button","title":"Custom links"},{"location":"manual/administration/extras/#jinja-templating","text":"Jinja templating can be used in the text or URL definition. The instance object of the current instance detail page is used as context. Full instance object definition can be retrieved through the API documentation . Instance spec example: { \"key1\" : \"value1\" } Button text example: Button {{ instance.name }} Button url example: https://external_resource.domain/?name={{ instance.spec.key1 }} Rendered button with an instance named \"k8S ns test\": < a href = \"https://external_resource.domain/?name=value1\" > Button k8S ns test </ a >","title":"Jinja templating"},{"location":"manual/administration/extras/#when-condition","text":"The when condition allow to display the button only on certain condition like the \"when\" flag on Ansible. E.g: spec['configvar'] == 'value' and user_spec['other'] == 'value' Note Like for Ansible, double curly braces are not used in 'when' declaration.","title":"When condition"},{"location":"manual/administration/extras/#loop","text":"When the loop definition is set, a dropdown button is created with a link for each element of the given list. Like for Ansible, the element is exposed as item in the Jinja template of the button text or URL. Instance spec example: { \"my_list\" : [ \"item1\" , \"item2\" ] } Loop example: {{ instance.spec.my_list }} Button text example: name: {{ item }} Button url example: https://external_resource.domain/{{ item }} Rendered links into the dropdown button: < a href = \"https://external_resource.domain/item1\" > name: item1 </ a > < a href = \"https://external_resource.domain/item2\" > name: item2 </ a >","title":"Loop"},{"location":"manual/administration/rbac/","text":"RBAC (Role Based Access Control) Role-based access control (RBAC), is a mechanism that restricts Squest access. It involves setting permissions to enable access to authorized users. Permissions are then grouped into Roles and given to a scope which can be a team or and organizations or global . RBAC is the link between a role, a scope and a user. The Squest RBAC system enable an administrator to grant users or groups the ability to perform an action on arbitrary subsets of objects in Squest. Permissions Permission in Squest represent a relationship with following components: Name: A short description of the permission. Codename: A unique identifier for the permission with camel case format. Content type: A Squest object (E.g: Request, Instance) For example, a permission named \"Can request a day2 operation on instance\" attached to the content type \"instance\". This permission is required, like the name is suggesting, to create a request for a day 2 operation on an existing instance. All objects have generic CRUD (Create, Retrieve/List, Update, Delete) permissions by default: create_object to create the object view_object to retrieve the object list_object to list object instances change_object to update the object delete_object to delete the object Note Full permission list is available in the RBAC section of your Squest instance. Specific Squest permissions: Short description Codename Object Can add users in global scope add_users_globalscope globalscope Can delete users in global scope delete_users_globalscope globalscope Can view users in global scope view_users_globalscope globalscope Can add users in organization add_users_organization organization Can delete users in organization delete_users_organization organization Can view users in organization view_users_organization organization Can consume quota of the scope consume_quota_scope scope Can add users in team add_users_team team Can delete users in team delete_users_team team Can view users in team view_users_team team Can approve/reject an approval step approve_reject_approvalstep approvalstep Can view admin custom link view_admin_customlink customlink Can request an admin day2 operation on instance admin_request_on_instance instance Can archive instance archive_instance instance Can change admin spec on instance change_admin_spec_instance instance Can request a day2 operation on instance request_on_instance instance Can unarchive instance unarchive_instance instance Can view admin spec on instance view_admin_spec_instance instance Can accept request accept_request request Can archive request archive_request request Can cancel request cancel_request request Can ask info request need_info_request request Can process request process_request request Can reject request reject_request request Can re-submit request re_submit_request request Can unarchive request unarchive_request request Can request an admin operation on service admin_request_on_service service Can request operation on service request_on_service service Can close support close_support support Can reopen support reopen_support support Can sync RHAAP/AWX sync_towerserver towerserver Note New permissions can be created in the context of approval steps . Global permissions Global permissions are permissions granted to all logged Squest user. Permissions are purely additive (there are no \"deny\" rules). Warning Changing the list of global permissions may impact the global bahavior of Squest. Use with caution. Owner permissions Owner permissions are permissions granted to the owner of an Instance, Request or Support. Are considered as owner: requester for Instance user for Request opened_by for Support Configuring \"view_instance\" permissions within the Owner Permissions will grant users the ability to see all instances for which they are the requester. Adding \"view_support\" permission will grant users the ability to see all supports related to their instances and supports they opened. Warning Changing the list of owner permissions may impact the global bahavior of Squest. Use with caution. Roles A role is a set of permissions. After creating a Role , you can assign it to a user though a team , an organization or globally . Giving a role to a scope gives permissions to all underlying objects of the scope.","title":"RBAC"},{"location":"manual/administration/rbac/#rbac-role-based-access-control","text":"Role-based access control (RBAC), is a mechanism that restricts Squest access. It involves setting permissions to enable access to authorized users. Permissions are then grouped into Roles and given to a scope which can be a team or and organizations or global . RBAC is the link between a role, a scope and a user. The Squest RBAC system enable an administrator to grant users or groups the ability to perform an action on arbitrary subsets of objects in Squest.","title":"RBAC (Role Based Access Control)"},{"location":"manual/administration/rbac/#permissions","text":"Permission in Squest represent a relationship with following components: Name: A short description of the permission. Codename: A unique identifier for the permission with camel case format. Content type: A Squest object (E.g: Request, Instance) For example, a permission named \"Can request a day2 operation on instance\" attached to the content type \"instance\". This permission is required, like the name is suggesting, to create a request for a day 2 operation on an existing instance. All objects have generic CRUD (Create, Retrieve/List, Update, Delete) permissions by default: create_object to create the object view_object to retrieve the object list_object to list object instances change_object to update the object delete_object to delete the object Note Full permission list is available in the RBAC section of your Squest instance. Specific Squest permissions: Short description Codename Object Can add users in global scope add_users_globalscope globalscope Can delete users in global scope delete_users_globalscope globalscope Can view users in global scope view_users_globalscope globalscope Can add users in organization add_users_organization organization Can delete users in organization delete_users_organization organization Can view users in organization view_users_organization organization Can consume quota of the scope consume_quota_scope scope Can add users in team add_users_team team Can delete users in team delete_users_team team Can view users in team view_users_team team Can approve/reject an approval step approve_reject_approvalstep approvalstep Can view admin custom link view_admin_customlink customlink Can request an admin day2 operation on instance admin_request_on_instance instance Can archive instance archive_instance instance Can change admin spec on instance change_admin_spec_instance instance Can request a day2 operation on instance request_on_instance instance Can unarchive instance unarchive_instance instance Can view admin spec on instance view_admin_spec_instance instance Can accept request accept_request request Can archive request archive_request request Can cancel request cancel_request request Can ask info request need_info_request request Can process request process_request request Can reject request reject_request request Can re-submit request re_submit_request request Can unarchive request unarchive_request request Can request an admin operation on service admin_request_on_service service Can request operation on service request_on_service service Can close support close_support support Can reopen support reopen_support support Can sync RHAAP/AWX sync_towerserver towerserver Note New permissions can be created in the context of approval steps .","title":"Permissions"},{"location":"manual/administration/rbac/#global-permissions","text":"Global permissions are permissions granted to all logged Squest user. Permissions are purely additive (there are no \"deny\" rules). Warning Changing the list of global permissions may impact the global bahavior of Squest. Use with caution.","title":"Global permissions"},{"location":"manual/administration/rbac/#owner-permissions","text":"Owner permissions are permissions granted to the owner of an Instance, Request or Support. Are considered as owner: requester for Instance user for Request opened_by for Support Configuring \"view_instance\" permissions within the Owner Permissions will grant users the ability to see all instances for which they are the requester. Adding \"view_support\" permission will grant users the ability to see all supports related to their instances and supports they opened. Warning Changing the list of owner permissions may impact the global bahavior of Squest. Use with caution.","title":"Owner permissions"},{"location":"manual/administration/rbac/#roles","text":"A role is a set of permissions. After creating a Role , you can assign it to a user though a team , an organization or globally . Giving a role to a scope gives permissions to all underlying objects of the scope.","title":"Roles"},{"location":"manual/administration/rhaap/","text":"RHAAP/AWX Squest need to be connected to a RHAAP (Red Hat Ansible Automation Platform) or AWX controller in order to work. Operations in Squest services are actually pointers to job templates in those controllers. Squest will need a token in order to communicate to the API of your RHAAP/AWX instance. RHAAP/AWX configuration Create an application: On RHAAP/AWX, go in Application menu and create a new app with the following configuration: name: squest Organization: Default Authorization grant type: Resource owner password based Client type: Confidential Create a token: Go in your Profile page (top right corner), go into the tokens section Click add button Search for the \"squest\" application created previously and select it Give a scope \"write\" Save and copy the generated token. This will be the token to give to Squest when creating a new RHAAP/AWX server instance. Add a controller in Squest Configuration: Name Description Name Short name of the RHAAP/AWX controller Host FQDN of the server to connect with the port (no protocol). E.g: awx.mydomain.net:8043 Token Token created from the previous section Is secure Enable this flag if the protocol is HTTPS (by default) SSL verify Enable this flag to check the server certificate Extra vars Add extra vars in json format that will be sent on every job of this controller","title":"RHAAP/AWX"},{"location":"manual/administration/rhaap/#rhaapawx","text":"Squest need to be connected to a RHAAP (Red Hat Ansible Automation Platform) or AWX controller in order to work. Operations in Squest services are actually pointers to job templates in those controllers. Squest will need a token in order to communicate to the API of your RHAAP/AWX instance.","title":"RHAAP/AWX"},{"location":"manual/administration/rhaap/#rhaapawx-configuration","text":"Create an application: On RHAAP/AWX, go in Application menu and create a new app with the following configuration: name: squest Organization: Default Authorization grant type: Resource owner password based Client type: Confidential Create a token: Go in your Profile page (top right corner), go into the tokens section Click add button Search for the \"squest\" application created previously and select it Give a scope \"write\" Save and copy the generated token. This will be the token to give to Squest when creating a new RHAAP/AWX server instance.","title":"RHAAP/AWX configuration"},{"location":"manual/administration/rhaap/#add-a-controller-in-squest","text":"Configuration: Name Description Name Short name of the RHAAP/AWX controller Host FQDN of the server to connect with the port (no protocol). E.g: awx.mydomain.net:8043 Token Token created from the previous section Is secure Enable this flag if the protocol is HTTPS (by default) SSL verify Enable this flag to check the server certificate Extra vars Add extra vars in json format that will be sent on every job of this controller","title":"Add a controller in Squest"},{"location":"manual/advanced/filters/","text":"JSON Accessor In the Squest UI, certain pages offer filtering options based on JSON accessors. For instance, the instance list page allows filtering based on instance specs. To access a field in json, simply describe the path by separating the levels by dots. The value of field to filter must be after an equal. It is possible to make a filter on several fields which are separated by commas. Examples Instance spec with string { \"vm_name\" : \"vm001\" } Examples of lookup string that can be used in the filter. vm_name=vm001 vm_name='vm001' vm_name=\"vm001\" Instance spec with dict { \"openstack\" : { \"cluster_name\" : \"cluster_perf\" } } Example of lookup string that can be used in the filter. openstack.cluster_name=cluster_perf Instance spec with list { \"vm_disk\" : [ \"disk01\" , \"disk02\" ] } Example of lookup string that can be used in the filter. vm_disk.0=disk01 Instance spec on two fields { \"my_first_field\" : { \"my_second_field\" : [ \"my_value1\" , \"my_value2\" ] }, \"my_integer_field\" : 1 } Example of lookup string that can be used in the filter. my_first_field.my_second_field.0=my_value1,my_integer_field=1 Instance spec with regex { \"dns_name\" : \"my_hostname.domain.example\" } Lookup string example: dns_name.regex=my_hostname","title":"JSON Accessor"},{"location":"manual/advanced/filters/#json-accessor","text":"In the Squest UI, certain pages offer filtering options based on JSON accessors. For instance, the instance list page allows filtering based on instance specs. To access a field in json, simply describe the path by separating the levels by dots. The value of field to filter must be after an equal. It is possible to make a filter on several fields which are separated by commas.","title":"JSON Accessor"},{"location":"manual/advanced/filters/#examples","text":"","title":"Examples"},{"location":"manual/advanced/filters/#instance-spec-with-string","text":"{ \"vm_name\" : \"vm001\" } Examples of lookup string that can be used in the filter. vm_name=vm001 vm_name='vm001' vm_name=\"vm001\"","title":"Instance spec with string"},{"location":"manual/advanced/filters/#instance-spec-with-dict","text":"{ \"openstack\" : { \"cluster_name\" : \"cluster_perf\" } } Example of lookup string that can be used in the filter. openstack.cluster_name=cluster_perf","title":"Instance spec with dict"},{"location":"manual/advanced/filters/#instance-spec-with-list","text":"{ \"vm_disk\" : [ \"disk01\" , \"disk02\" ] } Example of lookup string that can be used in the filter. vm_disk.0=disk01","title":"Instance spec with list"},{"location":"manual/advanced/filters/#instance-spec-on-two-fields","text":"{ \"my_first_field\" : { \"my_second_field\" : [ \"my_value1\" , \"my_value2\" ] }, \"my_integer_field\" : 1 } Example of lookup string that can be used in the filter. my_first_field.my_second_field.0=my_value1,my_integer_field=1","title":"Instance spec on two fields"},{"location":"manual/advanced/filters/#instance-spec-with-regex","text":"{ \"dns_name\" : \"my_hostname.domain.example\" } Lookup string example: dns_name.regex=my_hostname","title":"Instance spec with regex"},{"location":"manual/advanced/jinja/","text":"Jinja templating Jinja templating is applicable within specific sections of the Squest configuration. For example, Jinja templating enables the prefilling of a survey field for a day 2 operation using the specs of the instance. Jinja templating usage with {{ instance }} as context: Custom links Operation survey default field config Jinja templating usage with {{ request }} as context: Operation job template config (inventory, credentials, tags, limit) Approval workflow step Jinja templating usage with {{ user }} as context: Operation survey default field config Examples String with no jinja Even if the context is sent, a hard coded string can be used without using it. Jinja string My hard coded value Result My hard coded value Using the instance as context Accessing instance name: Instance context { \"id\" : 1 , \"state\" : 10 , \"resources\" : [], \"requester\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : true , \"is_active\" : true , \"groups\" : [] }, \"quota_scope\" : { \"id\" : 1 , \"rbac\" : [], \"name\" : \"test_scope\" , \"description\" : \"\" , \"roles\" : [] }, \"name\" : \"test\" , \"spec\" : { \"os\" : \"linux\" }, \"user_spec\" : { \"vCPU\" : 2 , \"memory\" : 4 , }, \"date_available\" : null , \"service\" : 1 } Jinja string My hard coded value with {{ instance.name }} Result My hard coded value with my_instance Accessing instance spec: Instance context { \"id\" : 1 , \"state\" : 10 , \"resources\" : [], \"requester\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : true , \"is_active\" : true , \"groups\" : [] }, \"quota_scope\" : { \"id\" : 1 , \"rbac\" : [], \"name\" : \"test_scope\" , \"description\" : \"\" , \"roles\" : [] }, \"name\" : \"test\" , \"spec\" : { \"os\" : \"linux\" }, \"user_spec\" : { \"vCPU\" : 2 , \"memory\" : 4 , }, \"date_available\" : null , \"service\" : 1 } Jinja string {{ instance.spec.os }} Result linux Note The spec and user_spec variables are only usable on Update or Delete operations as the pending instance does not contain any spec before its provisioning. Note If the given variable key doesn't exist, the default value will be set to an empty string. Using the request as context This example, used in the \"default limit\" of the operation job template config, allows to automatically configure the inventory limit following the given \"dns\" field of the survey. Instance context { \"id\" : 1 , \"instance\" : { \"id\" : 1 , \"state\" : 10 , \"resources\" : [], \"requester\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : false , \"is_active\" : true , \"groups\" : [] }, \"quota_scope\" : { \"id\" : 1 , \"rbac\" : [], \"created\" : \"2023-09-15T14:39:00.662779+02:00\" , \"last_updated\" : \"2023-09-15T14:39:00.675268+02:00\" , \"name\" : \"test\" , \"description\" : \"\" , \"roles\" : [] }, \"created\" : \"2023-09-15T14:39:03.321285+02:00\" , \"last_updated\" : \"2023-09-15T14:39:03.367724+02:00\" , \"name\" : \"test\" , \"spec\" : { \"os\" : \"linux\" }, \"user_spec\" : { \"vCPU\" : 2 , \"memory\" : 4 , }, \"date_available\" : null , \"service\" : 1 }, \"user\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : true , \"is_active\" : true , \"groups\" : [] }, \"created\" : \"2023-09-15T14:39:03.545051+02:00\" , \"last_updated\" : \"2023-09-15T14:39:03.590197+02:00\" , \"fill_in_survey\" : { \"vm_os\" : \"rhel8.5\" }, \"admin_fill_in_survey\" : {}, \"date_submitted\" : \"2022-08-30T14:46:05.856352+02:00\" , \"date_complete\" : \"2022-08-30T17:05:05.356421+02:00\" , \"date_archived\" : null , \"tower_job_id\" : 1 , \"state\" : 7 , \"operation\" : 9 , \"accepted_by\" : null , \"processed_by\" : null , \"approval_workflow_state\" : null } Jinja string {{ request.fill_in_survey.dns }} Result vm-name.domain.com Dict access Instance JSON spec { \"spec\" : { \"os\" : { \"linux\" : \"ubuntu\" } } } Jinja string {{ instance.spec.os['linux'] }} Result ubuntu List access Instance JSON spec { \"spec\" : { \"os\" : [ \"linux\" , \"windows\" ] }, \"user_spec\" : {} } Jinja string {{ spec.os[1] }} Result windows Filters Jinja filters can also be used to transform variables. For example, the 'select multiple' field type requires a list of string separated with a carriage return marker ( \\n ). Instance JSON spec { \"spec\" : { \"os\" : [ \"linux\" , \"windows\" ] }, \"user_spec\" : {} } Jinja string {{ spec.os | join('\\n') }} Result linux\\nwindows Conditions In this example, the target inventory ID is changed following a survey variable is_prod . Instance JSON spec { \"spec\" : { \"is_prod\" : true }, \"user_spec\" : {} } Jinja string {% if is_prod %}1{% else %}3{% endif %} Result linux\\nwindows","title":"Jinja templating"},{"location":"manual/advanced/jinja/#jinja-templating","text":"Jinja templating is applicable within specific sections of the Squest configuration. For example, Jinja templating enables the prefilling of a survey field for a day 2 operation using the specs of the instance. Jinja templating usage with {{ instance }} as context: Custom links Operation survey default field config Jinja templating usage with {{ request }} as context: Operation job template config (inventory, credentials, tags, limit) Approval workflow step Jinja templating usage with {{ user }} as context: Operation survey default field config","title":"Jinja templating"},{"location":"manual/advanced/jinja/#examples","text":"","title":"Examples"},{"location":"manual/advanced/jinja/#string-with-no-jinja","text":"Even if the context is sent, a hard coded string can be used without using it. Jinja string My hard coded value Result My hard coded value","title":"String with no jinja"},{"location":"manual/advanced/jinja/#using-the-instance-as-context","text":"Accessing instance name: Instance context { \"id\" : 1 , \"state\" : 10 , \"resources\" : [], \"requester\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : true , \"is_active\" : true , \"groups\" : [] }, \"quota_scope\" : { \"id\" : 1 , \"rbac\" : [], \"name\" : \"test_scope\" , \"description\" : \"\" , \"roles\" : [] }, \"name\" : \"test\" , \"spec\" : { \"os\" : \"linux\" }, \"user_spec\" : { \"vCPU\" : 2 , \"memory\" : 4 , }, \"date_available\" : null , \"service\" : 1 } Jinja string My hard coded value with {{ instance.name }} Result My hard coded value with my_instance Accessing instance spec: Instance context { \"id\" : 1 , \"state\" : 10 , \"resources\" : [], \"requester\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : true , \"is_active\" : true , \"groups\" : [] }, \"quota_scope\" : { \"id\" : 1 , \"rbac\" : [], \"name\" : \"test_scope\" , \"description\" : \"\" , \"roles\" : [] }, \"name\" : \"test\" , \"spec\" : { \"os\" : \"linux\" }, \"user_spec\" : { \"vCPU\" : 2 , \"memory\" : 4 , }, \"date_available\" : null , \"service\" : 1 } Jinja string {{ instance.spec.os }} Result linux Note The spec and user_spec variables are only usable on Update or Delete operations as the pending instance does not contain any spec before its provisioning. Note If the given variable key doesn't exist, the default value will be set to an empty string.","title":"Using the instance as context"},{"location":"manual/advanced/jinja/#using-the-request-as-context","text":"This example, used in the \"default limit\" of the operation job template config, allows to automatically configure the inventory limit following the given \"dns\" field of the survey. Instance context { \"id\" : 1 , \"instance\" : { \"id\" : 1 , \"state\" : 10 , \"resources\" : [], \"requester\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : false , \"is_active\" : true , \"groups\" : [] }, \"quota_scope\" : { \"id\" : 1 , \"rbac\" : [], \"created\" : \"2023-09-15T14:39:00.662779+02:00\" , \"last_updated\" : \"2023-09-15T14:39:00.675268+02:00\" , \"name\" : \"test\" , \"description\" : \"\" , \"roles\" : [] }, \"created\" : \"2023-09-15T14:39:03.321285+02:00\" , \"last_updated\" : \"2023-09-15T14:39:03.367724+02:00\" , \"name\" : \"test\" , \"spec\" : { \"os\" : \"linux\" }, \"user_spec\" : { \"vCPU\" : 2 , \"memory\" : 4 , }, \"date_available\" : null , \"service\" : 1 }, \"user\" : { \"id\" : 3 , \"username\" : \"admin@squest.com\" , \"email\" : \"admin@squest.com\" , \"profile\" : { \"request_notification_enabled\" : true , \"instance_notification_enabled\" : true , \"request_notification_filters\" : [], \"instance_notification_filters\" : [] }, \"first_name\" : \"admin\" , \"last_name\" : \"squest\" , \"is_staff\" : true , \"is_superuser\" : true , \"is_active\" : true , \"groups\" : [] }, \"created\" : \"2023-09-15T14:39:03.545051+02:00\" , \"last_updated\" : \"2023-09-15T14:39:03.590197+02:00\" , \"fill_in_survey\" : { \"vm_os\" : \"rhel8.5\" }, \"admin_fill_in_survey\" : {}, \"date_submitted\" : \"2022-08-30T14:46:05.856352+02:00\" , \"date_complete\" : \"2022-08-30T17:05:05.356421+02:00\" , \"date_archived\" : null , \"tower_job_id\" : 1 , \"state\" : 7 , \"operation\" : 9 , \"accepted_by\" : null , \"processed_by\" : null , \"approval_workflow_state\" : null } Jinja string {{ request.fill_in_survey.dns }} Result vm-name.domain.com","title":"Using the request as context"},{"location":"manual/advanced/jinja/#dict-access","text":"Instance JSON spec { \"spec\" : { \"os\" : { \"linux\" : \"ubuntu\" } } } Jinja string {{ instance.spec.os['linux'] }} Result ubuntu","title":"Dict access"},{"location":"manual/advanced/jinja/#list-access","text":"Instance JSON spec { \"spec\" : { \"os\" : [ \"linux\" , \"windows\" ] }, \"user_spec\" : {} } Jinja string {{ spec.os[1] }} Result windows","title":"List access"},{"location":"manual/advanced/jinja/#filters","text":"Jinja filters can also be used to transform variables. For example, the 'select multiple' field type requires a list of string separated with a carriage return marker ( \\n ). Instance JSON spec { \"spec\" : { \"os\" : [ \"linux\" , \"windows\" ] }, \"user_spec\" : {} } Jinja string {{ spec.os | join('\\n') }} Result linux\\nwindows","title":"Filters"},{"location":"manual/advanced/jinja/#conditions","text":"In this example, the target inventory ID is changed following a survey variable is_prod . Instance JSON spec { \"spec\" : { \"is_prod\" : true }, \"user_spec\" : {} } Jinja string {% if is_prod %}1{% else %}3{% endif %} Result linux\\nwindows","title":"Conditions"},{"location":"manual/advanced/validators/","text":"Field validators Field validators are Python modules that can be added as plugin to perform custom checks on an operation survey field . Create a field validator Validators are based on the Django and Django Rest Framework API. Django validators doc Django Rest framework validators doc Create a python file that contains 2 methods that receive a value as parameter. The methods must be named validate_api and validate_ui . Validators methods takes a value and raises a ValidationError if it does not meet some criteria. The validate_api must raise a django.core.exceptions.ValidationError in case of error. The validate_ui must raise a rest_framework.serializers.ValidationError in case of error. Here is an example of file that check if the given value of the field is even: from django.core.exceptions import ValidationError from rest_framework import serializers from django.utils.translation import ugettext as _ def validate_api ( value ): if int ( value ) % 2 != 0 : raise serializers . ValidationError ( 'This field must be an even number.' ) def validate_ui ( value ): try : if int ( value ) % 2 != 0 : raise ValidationError ( _ ( ' %(value)s is not an even number' ), params = { 'value' : value }, ) except ValueError : # given value cannot be cast into an integer pass Add your validators to the deployment Place your scripts in a folder on the machine that host Squest. E.g: tree /tmp/squest_plugins /tmp/squest_plugins \u2514\u2500\u2500 field_validators \u251c\u2500\u2500 even_number.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 superior_to_10.py Update the docker-compose.yml file to add a volume that map your script folder to the plugin folder in the Django container: django : &django image : quay.io/hewlettpackardenterprise/squest:latest env_file : docker/environment_variables/squest.env environment : WAIT_HOSTS : db:3306,rabbitmq:5672 volumes : - django_static:/app/static - django_media:/app/media - backup:/app/backup - /tmp/squest_plugins/field_validators:/app/plugins/field_validators # update this line depends_on : - db - rabbitmq - celery-worker - celery-beat - redis-cache Set validator to a form field In squest, go into Service Catalog --> Manage Services --> Operations --> Survey For each field of the RHAAP/AWX survey of the selected operation you can now add one or more validator.","title":"Field validators"},{"location":"manual/advanced/validators/#field-validators","text":"Field validators are Python modules that can be added as plugin to perform custom checks on an operation survey field .","title":"Field validators"},{"location":"manual/advanced/validators/#create-a-field-validator","text":"Validators are based on the Django and Django Rest Framework API. Django validators doc Django Rest framework validators doc Create a python file that contains 2 methods that receive a value as parameter. The methods must be named validate_api and validate_ui . Validators methods takes a value and raises a ValidationError if it does not meet some criteria. The validate_api must raise a django.core.exceptions.ValidationError in case of error. The validate_ui must raise a rest_framework.serializers.ValidationError in case of error. Here is an example of file that check if the given value of the field is even: from django.core.exceptions import ValidationError from rest_framework import serializers from django.utils.translation import ugettext as _ def validate_api ( value ): if int ( value ) % 2 != 0 : raise serializers . ValidationError ( 'This field must be an even number.' ) def validate_ui ( value ): try : if int ( value ) % 2 != 0 : raise ValidationError ( _ ( ' %(value)s is not an even number' ), params = { 'value' : value }, ) except ValueError : # given value cannot be cast into an integer pass","title":"Create a field validator"},{"location":"manual/advanced/validators/#add-your-validators-to-the-deployment","text":"Place your scripts in a folder on the machine that host Squest. E.g: tree /tmp/squest_plugins /tmp/squest_plugins \u2514\u2500\u2500 field_validators \u251c\u2500\u2500 even_number.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 superior_to_10.py Update the docker-compose.yml file to add a volume that map your script folder to the plugin folder in the Django container: django : &django image : quay.io/hewlettpackardenterprise/squest:latest env_file : docker/environment_variables/squest.env environment : WAIT_HOSTS : db:3306,rabbitmq:5672 volumes : - django_static:/app/static - django_media:/app/media - backup:/app/backup - /tmp/squest_plugins/field_validators:/app/plugins/field_validators # update this line depends_on : - db - rabbitmq - celery-worker - celery-beat - redis-cache","title":"Add your validators to the deployment"},{"location":"manual/advanced/validators/#set-validator-to-a-form-field","text":"In squest, go into Service Catalog --> Manage Services --> Operations --> Survey For each field of the RHAAP/AWX survey of the selected operation you can now add one or more validator.","title":"Set validator to a form field"},{"location":"manual/resource_tracking/attributes/","text":"Attributes Attributes are variable definition of a Resource . Attribute are declared once and can then be used by Resource Group . For example, to manage Kubernetes namespace (as Resource Group) you could create following attributes: request.cpu request.memory limit.cpu limit.memory Attributes and quota Attributes are defined in the resource tracking and then Set as quota on organizations or teams Attached to fields of the survey of an operation in the service catalog So when a user make a request for a new service in the service catalog, some fields from the survey can be limited to the quota defined behind the attribute. When a resource is linked to an instance of the service catalog , the quota consumed is automatically updated.","title":"Attribute"},{"location":"manual/resource_tracking/attributes/#attributes","text":"Attributes are variable definition of a Resource . Attribute are declared once and can then be used by Resource Group . For example, to manage Kubernetes namespace (as Resource Group) you could create following attributes: request.cpu request.memory limit.cpu limit.memory","title":"Attributes"},{"location":"manual/resource_tracking/attributes/#attributes-and-quota","text":"Attributes are defined in the resource tracking and then Set as quota on organizations or teams Attached to fields of the survey of an operation in the service catalog So when a user make a request for a new service in the service catalog, some fields from the survey can be limited to the quota defined behind the attribute. When a resource is linked to an instance of the service catalog , the quota consumed is automatically updated.","title":"Attributes and quota"},{"location":"manual/resource_tracking/concept/","text":"Resource tracking Nowadays, IT infrastructures are composed of multiple layers. Physical servers, virtual machines, containers, storage,... Each layer is consumer or a producer of resources of another layer. As an IT administrator, we need to monitor resource consumption of a top layers to be sure that we can provide services on underlying layers. The resource tracking feature allows to monitor reserved resources and highlight available resource in an infrastructure. It's also a way to set quota to Note This feature is not a real time monitoring. It does not connect to you infrastructure to check the real consumption but help to follow what resources have been reserved to avoid overallocation when accepting new request from the service catalog. Concept VM tracking example To introduce the concept of attributes , resources and resource groups , lets take the example of a virtualization stack. A virtualization stack is composed of a group of physical machines, that are added to an hypervisor and create what we usually call a \"cluster\". The cluster would be, in Squest, a Resource Group . Everytime we add a new physical machine to the cluster, the total amount of resource available increases. A machine is, in this case, a Resource of the Resource Group . The amount of resource correspond to the physical server specifications like CPU , memory or disk . Those specs are the Attributes of a Resource . Starting from the previous state, we can then create a Resource Group for virtual machines that will consume resources from the \"cluster\" Resource Group . \"VMs\" is another Resource Group , with their own attributes named vCPU and v_memory that will consume respectively on attributes from the upper Resource Group \"cluster\" on CPU and memory . If we want to add more VMs that consume resources from the \"cluster\" Resource Group , we need to be sure we have enough physical servers (resources) that produce into it. Kubernetes tracking example In this example we want to track the consumption of an orchestrator of container like Kubernetes or Openshift. Namespaces (or projects in Openshift world) are a way to divide cluster resources between multiple users by using resource quota. Openshift and Kubernetes frameworks are commonly deployed in a virtual machines. So we retrieve layers from previous example with bare metal servers that produce resources in a cluster of our hypervisor. Orchestrators are usually composed of 2 kind of node: Masters and Workers. Master VMs are used by the infrastructure itself and workers for user's workloads, aka namespaces. As namespaces are only executed in \"worker\" nodes, we need to declare 2 different resource group : \"Master\" and \"Worker\" VMs. The aggregation of resources of all workers compose amount of available resources that the namespaces resource group can theoretically consume. The complete resource tracking definition would look like the following: With this definition, we are able to determine there is enough available resources in each layer to handle underlying objects. Adding a new namespace in the last resource group K8S namespaces will generate more consumption. If this last layer resource group is lacking of resources, adding more worker node in the Worker VMs resource group will be required, generating consumption on the upper layer Cluster and so on...","title":"Concept"},{"location":"manual/resource_tracking/concept/#resource-tracking","text":"Nowadays, IT infrastructures are composed of multiple layers. Physical servers, virtual machines, containers, storage,... Each layer is consumer or a producer of resources of another layer. As an IT administrator, we need to monitor resource consumption of a top layers to be sure that we can provide services on underlying layers. The resource tracking feature allows to monitor reserved resources and highlight available resource in an infrastructure. It's also a way to set quota to Note This feature is not a real time monitoring. It does not connect to you infrastructure to check the real consumption but help to follow what resources have been reserved to avoid overallocation when accepting new request from the service catalog.","title":"Resource tracking"},{"location":"manual/resource_tracking/concept/#concept","text":"","title":"Concept"},{"location":"manual/resource_tracking/concept/#vm-tracking-example","text":"To introduce the concept of attributes , resources and resource groups , lets take the example of a virtualization stack. A virtualization stack is composed of a group of physical machines, that are added to an hypervisor and create what we usually call a \"cluster\". The cluster would be, in Squest, a Resource Group . Everytime we add a new physical machine to the cluster, the total amount of resource available increases. A machine is, in this case, a Resource of the Resource Group . The amount of resource correspond to the physical server specifications like CPU , memory or disk . Those specs are the Attributes of a Resource . Starting from the previous state, we can then create a Resource Group for virtual machines that will consume resources from the \"cluster\" Resource Group . \"VMs\" is another Resource Group , with their own attributes named vCPU and v_memory that will consume respectively on attributes from the upper Resource Group \"cluster\" on CPU and memory . If we want to add more VMs that consume resources from the \"cluster\" Resource Group , we need to be sure we have enough physical servers (resources) that produce into it.","title":"VM tracking example"},{"location":"manual/resource_tracking/concept/#kubernetes-tracking-example","text":"In this example we want to track the consumption of an orchestrator of container like Kubernetes or Openshift. Namespaces (or projects in Openshift world) are a way to divide cluster resources between multiple users by using resource quota. Openshift and Kubernetes frameworks are commonly deployed in a virtual machines. So we retrieve layers from previous example with bare metal servers that produce resources in a cluster of our hypervisor. Orchestrators are usually composed of 2 kind of node: Masters and Workers. Master VMs are used by the infrastructure itself and workers for user's workloads, aka namespaces. As namespaces are only executed in \"worker\" nodes, we need to declare 2 different resource group : \"Master\" and \"Worker\" VMs. The aggregation of resources of all workers compose amount of available resources that the namespaces resource group can theoretically consume. The complete resource tracking definition would look like the following: With this definition, we are able to determine there is enough available resources in each layer to handle underlying objects. Adding a new namespace in the last resource group K8S namespaces will generate more consumption. If this last layer resource group is lacking of resources, adding more worker node in the Worker VMs resource group will be required, generating consumption on the upper layer Cluster and so on...","title":"Kubernetes tracking example"},{"location":"manual/resource_tracking/resource/","text":"Resources A Resource is an instance of a Resource Group . One or more resource can be linked to the Service catalog \"instances\". Link a service catalog instance Resources can be created from the API. It allows to create automatically a new resource in a resource group when something is provisioned from the service catalog. In the example below, the playbook executed in RHAAP/AWX would have created a VM. At the end of the process we call the squest API to instantiate a resource in the right resource group to reflect the consumption. We link as well the pending instance(given by squest.instance.id ) to this resource via the flag service_catalog_instance . - name : Add resource in resource group example hosts : localhost connection : local gather_facts : false vars : squest_token : xxxxxxxxxxxxxx squest_bearer_token : \"Bearer {{ squest_token }}\" squest_api : \"http://127.0.0.1:8000/api/\" resource_group_vm_id : 8 squest : # this would be the data sent from squest as extra vars instance : id : 8 name : test service : 1 spec : { } state : PROVISIONING vm_name : \"test-vm\" vm_vcpu : 4 vm_memory : 16 desc : \"My description\" tasks : - name : Print info sent by Squest debug : var : squest # ----------------------- # PLACE HERE ALL THE MAGIC TO CREATE THE RESOURCE # ----------------------- - name : Create a resource in squest uri : url : \"{{ squest_api }}resource-tracker/resource/\" headers : Authorization : \"{{ squest_bearer_token }}\" method : POST status_code : 201 body_format : json body : name : \"{{ vm_name }}\" resource_group : \"{{ resource_group_vm_id }}\" service_catalog_instance : \"{{ squest['instance']['id'] }}\" resource_attributes : - name : \"vCPU\" value : \"{{ vm_vcpu }}\" - name : \"Memory\" value : \"{{ vm_memory }}\"","title":"Resource"},{"location":"manual/resource_tracking/resource/#resources","text":"A Resource is an instance of a Resource Group . One or more resource can be linked to the Service catalog \"instances\".","title":"Resources"},{"location":"manual/resource_tracking/resource/#link-a-service-catalog-instance","text":"Resources can be created from the API. It allows to create automatically a new resource in a resource group when something is provisioned from the service catalog. In the example below, the playbook executed in RHAAP/AWX would have created a VM. At the end of the process we call the squest API to instantiate a resource in the right resource group to reflect the consumption. We link as well the pending instance(given by squest.instance.id ) to this resource via the flag service_catalog_instance . - name : Add resource in resource group example hosts : localhost connection : local gather_facts : false vars : squest_token : xxxxxxxxxxxxxx squest_bearer_token : \"Bearer {{ squest_token }}\" squest_api : \"http://127.0.0.1:8000/api/\" resource_group_vm_id : 8 squest : # this would be the data sent from squest as extra vars instance : id : 8 name : test service : 1 spec : { } state : PROVISIONING vm_name : \"test-vm\" vm_vcpu : 4 vm_memory : 16 desc : \"My description\" tasks : - name : Print info sent by Squest debug : var : squest # ----------------------- # PLACE HERE ALL THE MAGIC TO CREATE THE RESOURCE # ----------------------- - name : Create a resource in squest uri : url : \"{{ squest_api }}resource-tracker/resource/\" headers : Authorization : \"{{ squest_bearer_token }}\" method : POST status_code : 201 body_format : json body : name : \"{{ vm_name }}\" resource_group : \"{{ resource_group_vm_id }}\" service_catalog_instance : \"{{ squest['instance']['id'] }}\" resource_attributes : - name : \"vCPU\" value : \"{{ vm_vcpu }}\" - name : \"Memory\" value : \"{{ vm_memory }}\"","title":"Link a service catalog instance"},{"location":"manual/resource_tracking/resource_group/","text":"Resource groups In Squest, a resource group is a group of object (resource) that are composed by the same Attributes . Resource groups can be linked to consume from each other. Attributes Attributes are declared in the resource group as a definition of the generic object through a tansformer Each resource then created in the resource group may have to fill the value for each declared attribute. Transformer Consume from another Resource Group Each attribute of a resource group can consume from another attribute of another resource group by using a Transformer . E.g: The vCPU attribute of the VMS resource group can consume form the CPU attribute of the \"cluster\" resource group . Factor The factor act as an over commitment. It allows you to specify whether resources consume more or less than expected. For example, if a host has 28 core processors and hyperthreading is enabled, that host will produce 56 vCPUs (28 cores x 2 threads per core). This can be reflected by configuring the factor on the vCPU attribute to 2 . Tags Tags are words that are attached to Resource Group and can then be used to filter the \"Graph\" representation of all Resource Group. Tags are intended to be used to specify identifying objects that are meaningful and relevant to users. Tags can be used to organize and select subsets of objects. Tags can be attached to objects at creation time and subsequently added and modified at any time. To add multiple tags: If the input doesn't contain any commas or double quotes, it is simply treated as a space-delimited list of tag names. If the input does contain either of these characters: Groups of characters which appear between double quotes take precedence as multi-word tags (so double quoted tag names may contain commas). An unclosed double quote will be ignored. Otherwise, if there are any unquoted commas in the input, it will be treated as comma-delimited. If not, it will be treated as space-delimited. Examples: Tag input string Resulting tags Notes apple ball cat [\"apple\", \"ball\", \"cat\"] No commas, so space delimited apple, ball cat [\"apple\", \"ball cat\"] Comma present, so comma delimited \"apple, ball\" cat dog [\"apple, ball\", \"cat\", \"dog\"] All commas are quoted, so space delimited \"apple, ball\", cat dog [\"apple, ball\", \"cat dog\"] Contains an unquoted comma, so comma delimited apple \"ball cat\" dog [\"apple\", \"ball cat\", \"dog\"] No commas, so space delimited \"apple\" \"ball dog [\"apple\", \"ball\", \"dog\"] Unclosed double quote is ignored","title":"Resource group"},{"location":"manual/resource_tracking/resource_group/#resource-groups","text":"In Squest, a resource group is a group of object (resource) that are composed by the same Attributes . Resource groups can be linked to consume from each other.","title":"Resource groups"},{"location":"manual/resource_tracking/resource_group/#attributes","text":"Attributes are declared in the resource group as a definition of the generic object through a tansformer Each resource then created in the resource group may have to fill the value for each declared attribute.","title":"Attributes"},{"location":"manual/resource_tracking/resource_group/#transformer","text":"","title":"Transformer"},{"location":"manual/resource_tracking/resource_group/#consume-from-another-resource-group","text":"Each attribute of a resource group can consume from another attribute of another resource group by using a Transformer . E.g: The vCPU attribute of the VMS resource group can consume form the CPU attribute of the \"cluster\" resource group .","title":"Consume from another Resource Group"},{"location":"manual/resource_tracking/resource_group/#factor","text":"The factor act as an over commitment. It allows you to specify whether resources consume more or less than expected. For example, if a host has 28 core processors and hyperthreading is enabled, that host will produce 56 vCPUs (28 cores x 2 threads per core). This can be reflected by configuring the factor on the vCPU attribute to 2 .","title":"Factor"},{"location":"manual/resource_tracking/resource_group/#tags","text":"Tags are words that are attached to Resource Group and can then be used to filter the \"Graph\" representation of all Resource Group. Tags are intended to be used to specify identifying objects that are meaningful and relevant to users. Tags can be used to organize and select subsets of objects. Tags can be attached to objects at creation time and subsequently added and modified at any time. To add multiple tags: If the input doesn't contain any commas or double quotes, it is simply treated as a space-delimited list of tag names. If the input does contain either of these characters: Groups of characters which appear between double quotes take precedence as multi-word tags (so double quoted tag names may contain commas). An unclosed double quote will be ignored. Otherwise, if there are any unquoted commas in the input, it will be treated as comma-delimited. If not, it will be treated as space-delimited. Examples: Tag input string Resulting tags Notes apple ball cat [\"apple\", \"ball\", \"cat\"] No commas, so space delimited apple, ball cat [\"apple\", \"ball cat\"] Comma present, so comma delimited \"apple, ball\" cat dog [\"apple, ball\", \"cat\", \"dog\"] All commas are quoted, so space delimited \"apple, ball\", cat dog [\"apple, ball\", \"cat dog\"] Contains an unquoted comma, so comma delimited apple \"ball cat\" dog [\"apple\", \"ball cat\", \"dog\"] No commas, so space delimited \"apple\" \"ball dog [\"apple\", \"ball\", \"dog\"] Unclosed double quote is ignored","title":"Tags"},{"location":"manual/service_catalog/concept/","text":"Concept Once Squest is linked to an RHAAP/AWX server, \"services\" can be added into the catalog. A service is composed of operations that are pointers to \"job templates\" present in RHAAP/AWX. A service has at least one operation of type CREATE that allows to provision the resource. A service can have then multiple operation of type UPDATE and DELETE that allow to manage the lifecycle of instances that have been created via the CREATE operation. Provisioning a service When a user request for the first time a service, an instance is created automatically and set to \"pending\" state on Squest. Once approved by the administrator, the request is sent to RHAAP/AWX to execute the linked job template. The executed job, aka the Ansible playbook, need to call back the Squest API in order to attach information (spec) to the pending instance. Squest provisioning workflow: sequenceDiagram participant User participant Admin participant Squest participant RHAAP/AWX User->>Squest: Request service Admin->>Squest: Approve Admin->>Squest: Process Squest->>RHAAP/AWX: Process Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Running RHAAP/AWX->>Squest: Instance spec <br> {'uuid': 34, 'name': 'instance_name'} Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Successful Squest->>User: Notify service ready The playbook will receive a squest extra variable that contains information of to the pending instance linked to the request in addition to all extra variables which come from the survey of the job template. Example of extra variables sent by Squest: squest : squest_host : http://squest.domain.local request : instance : id : 1 name : test service : 1 spec : file_name : foo.conf state : PROVISIONING spoc : 2 Specs related to the created instance are important in order to be sent later to a playbook in charge of updating this particular instance. Sent specs must contain unique IDs that allow to identify precisely the instance. (E.g: uuid of a VMware VM, namespace and cluster_api_url for an Openshift project) Playbook example: In the example below, we've configured a job template with a survey that ask for a variable named file_name . The playbook will: create the resource (the file) call Squest api to link spec of the created resource to the instance - name : Create a file hosts : localhost connection : local gather_facts : false vars : squest_token : 48c67f9c2429f2d3a1ee0e47daa00ffeef4fe744 squest_bearer_token : \"Bearer {{ squest_token }}\" squest_api_url : \"http://192.168.58.128:8000/api/\" tasks : - name : Print the job template survey variable debug : var : file_name - name : Print info sent by Squest debug : var : squest - name : Create a file with the given file_name ansible.builtin.file : path : \"/tmp/{{ file_name }}\" owner : user group : user mode : '0644' state : touch - name : Update spec of the instance via the squest API uri : url : \"{{ squest_api_url }}service-catalog/instance/{{ squest['request']['instance']['id'] }}/\" # do not forget the last slash headers : Authorization : \"{{ squest_bearer_token }}\" method : PATCH body : spec : file_name : \"{{ file_name }}\" status_code : 200 body_format : json Day 2 operations Day 2 operations are operations that update or delete existing resources. Note By default, recent version of RHAAP/AWX drop extra variables that are not declared in the survey. To be able to receive Squest extra vars you need to enable \"Prompt on Launch\" in the \"Variables\" section of you job template. This correspond to the flag \"ask_variables_on_launch\" of the job_template model on the RHAAP/AWX API. When a user creates a request for a day 2 operation of a provisioned instance, Squest automatically attach an extra_vars named squest that contains the instance spec sent by the playbook used to provision at first the resource. The playbook used to update the instance need to use info placed in squest variable to retrieve the real resource that need to be updated or deleted. The update playbook can send a new version of the instance to squest at the end of its process if required. sequenceDiagram participant User participant Admin participant Squest participant RHAAP/AWX User->>Squest: Request update Admin->>Squest: Approve Admin->>Squest: Process Squest->>RHAAP/AWX: Process - Extra vars:<br> {'squest': {'uuid': 34, 'name': 'instance_name'}} Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Running RHAAP/AWX->>Squest: Instance spec update <br> {'uuid': 34, 'name': 'instance_new_name} Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Successful Squest->>User: Notify service updated Playbook example: Example of extra vars sent by squest: squest : squest_host : http://squest.domain.local request : instance : id : 1 name : test-instance service : 1 spec : file_name : foo.conf spoc : 2 state : UPDATING string_to_place_in_file : \"this is a string\" In the example below, the update job template survey ask for a string_to_place_in_file variable. The playbook receive as well all information that help to retrieve the resource to update. In this example the resource is the file_name . - name : Update content of a file hosts : localhost connection : local gather_facts : false tasks : - name : Print the job template survey variable debug : var : string_to_place_in_file - name : Print info sent by Squest debug : var : squest - name : Add content into the file_name given by squest instance spec ansible.builtin.lineinfile : path : \"/tmp/{{ squest['request']['instance']['spec']['file_name'] }}\" line : \"{{ string_to_place_in_file }}\" create : yes","title":"Concept"},{"location":"manual/service_catalog/concept/#concept","text":"Once Squest is linked to an RHAAP/AWX server, \"services\" can be added into the catalog. A service is composed of operations that are pointers to \"job templates\" present in RHAAP/AWX. A service has at least one operation of type CREATE that allows to provision the resource. A service can have then multiple operation of type UPDATE and DELETE that allow to manage the lifecycle of instances that have been created via the CREATE operation.","title":"Concept"},{"location":"manual/service_catalog/concept/#provisioning-a-service","text":"When a user request for the first time a service, an instance is created automatically and set to \"pending\" state on Squest. Once approved by the administrator, the request is sent to RHAAP/AWX to execute the linked job template. The executed job, aka the Ansible playbook, need to call back the Squest API in order to attach information (spec) to the pending instance. Squest provisioning workflow: sequenceDiagram participant User participant Admin participant Squest participant RHAAP/AWX User->>Squest: Request service Admin->>Squest: Approve Admin->>Squest: Process Squest->>RHAAP/AWX: Process Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Running RHAAP/AWX->>Squest: Instance spec <br> {'uuid': 34, 'name': 'instance_name'} Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Successful Squest->>User: Notify service ready The playbook will receive a squest extra variable that contains information of to the pending instance linked to the request in addition to all extra variables which come from the survey of the job template. Example of extra variables sent by Squest: squest : squest_host : http://squest.domain.local request : instance : id : 1 name : test service : 1 spec : file_name : foo.conf state : PROVISIONING spoc : 2 Specs related to the created instance are important in order to be sent later to a playbook in charge of updating this particular instance. Sent specs must contain unique IDs that allow to identify precisely the instance. (E.g: uuid of a VMware VM, namespace and cluster_api_url for an Openshift project) Playbook example: In the example below, we've configured a job template with a survey that ask for a variable named file_name . The playbook will: create the resource (the file) call Squest api to link spec of the created resource to the instance - name : Create a file hosts : localhost connection : local gather_facts : false vars : squest_token : 48c67f9c2429f2d3a1ee0e47daa00ffeef4fe744 squest_bearer_token : \"Bearer {{ squest_token }}\" squest_api_url : \"http://192.168.58.128:8000/api/\" tasks : - name : Print the job template survey variable debug : var : file_name - name : Print info sent by Squest debug : var : squest - name : Create a file with the given file_name ansible.builtin.file : path : \"/tmp/{{ file_name }}\" owner : user group : user mode : '0644' state : touch - name : Update spec of the instance via the squest API uri : url : \"{{ squest_api_url }}service-catalog/instance/{{ squest['request']['instance']['id'] }}/\" # do not forget the last slash headers : Authorization : \"{{ squest_bearer_token }}\" method : PATCH body : spec : file_name : \"{{ file_name }}\" status_code : 200 body_format : json","title":"Provisioning a service"},{"location":"manual/service_catalog/concept/#day-2-operations","text":"Day 2 operations are operations that update or delete existing resources. Note By default, recent version of RHAAP/AWX drop extra variables that are not declared in the survey. To be able to receive Squest extra vars you need to enable \"Prompt on Launch\" in the \"Variables\" section of you job template. This correspond to the flag \"ask_variables_on_launch\" of the job_template model on the RHAAP/AWX API. When a user creates a request for a day 2 operation of a provisioned instance, Squest automatically attach an extra_vars named squest that contains the instance spec sent by the playbook used to provision at first the resource. The playbook used to update the instance need to use info placed in squest variable to retrieve the real resource that need to be updated or deleted. The update playbook can send a new version of the instance to squest at the end of its process if required. sequenceDiagram participant User participant Admin participant Squest participant RHAAP/AWX User->>Squest: Request update Admin->>Squest: Approve Admin->>Squest: Process Squest->>RHAAP/AWX: Process - Extra vars:<br> {'squest': {'uuid': 34, 'name': 'instance_name'}} Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Running RHAAP/AWX->>Squest: Instance spec update <br> {'uuid': 34, 'name': 'instance_new_name} Squest-->>RHAAP/AWX: Check Note right of RHAAP/AWX: Successful Squest->>User: Notify service updated Playbook example: Example of extra vars sent by squest: squest : squest_host : http://squest.domain.local request : instance : id : 1 name : test-instance service : 1 spec : file_name : foo.conf spoc : 2 state : UPDATING string_to_place_in_file : \"this is a string\" In the example below, the update job template survey ask for a string_to_place_in_file variable. The playbook receive as well all information that help to retrieve the resource to update. In this example the resource is the file_name . - name : Update content of a file hosts : localhost connection : local gather_facts : false tasks : - name : Print the job template survey variable debug : var : string_to_place_in_file - name : Print info sent by Squest debug : var : squest - name : Add content into the file_name given by squest instance spec ansible.builtin.lineinfile : path : \"/tmp/{{ squest['request']['instance']['spec']['file_name'] }}\" line : \"{{ string_to_place_in_file }}\" create : yes","title":"Day 2 operations"},{"location":"manual/service_catalog/operation/","text":"Operation An Operation is an action attached to a service that can be requested by the end user. A service in Squest has at least one operation of type \"create\" which allows to create an instance of the service. Operations of type \"update\" or \"delete\" can be then added to manage the lifecycle of created instances of the service. Configuration Name Description Name Short name of the operation Description Small description of the operation Job template Executed job template in the backend RHAAP/AWX server Operation type Type of operation (Create, update, delete). Change the state of he instance after executing the operation Process timeout Number of second to wait for a successful return from the executed job template Auto accept If set to True a submitted request for this operation will be automatically accepted Auto process If set to True an accepted request for this operation will be automatically processed Enabled If set to True the operation can be requested from the UI and API Admin operation If set to True the admin_request_on_instance permission is required to request this operation Extra vars Set of extra vars as JSON Default inventory ID ID of the RHAAP/AWX inventory to use by default. Leave blank to use the default Job Template inventory Default limit Comma separated list of inventory host limits Default tags Comma separated list of tags to use Default skip tags Comma separated list of tags to skip Default verbosity Verbosity level (integer) Default job type Job type (Run or Check) Default diff mode Default False . This is equivalent to Ansible's --diff mode in the CLI Default credential IDs Comma separated list of credentials ID Job template config By default, Squest will execute the selected Job Template with the config as set in RHAAP/AWX. If a field is configured to \"Prompt on launch\" in RHAAP/AWX, the administrator can override it from the \"Process\" page of an accepted request: Overridable fields: Inventory (ID) Limit (hosts) Tags Skip tags Verbosity Job type Diff mode (Show changes) Credentials (Comma separated list of ID) The \"default\" configuration set at operation level allow to automatically pre-fill the \"Process\" page with values. Jinja templating can be used in the default value based on the current {{ request }} object as context. Examples can be retrieved in the dedicated documentation section . Full request object definition can be retrieved through the API documentation . Default value precedence: flowchart LR RHAAP/AWX(Default from RHAAP/AWX) --> Squest(Default from Squest) --> Process(Process request page) Note Default inventory ID field is expecting an integer that correspond the the inventory ID in RHAAP/AWX. Default credential IDs field is expecting a comma separated list of integer that correspond existings credentials ID in RHAAP/AWX.","title":"Operation"},{"location":"manual/service_catalog/operation/#operation","text":"An Operation is an action attached to a service that can be requested by the end user. A service in Squest has at least one operation of type \"create\" which allows to create an instance of the service. Operations of type \"update\" or \"delete\" can be then added to manage the lifecycle of created instances of the service.","title":"Operation"},{"location":"manual/service_catalog/operation/#configuration","text":"Name Description Name Short name of the operation Description Small description of the operation Job template Executed job template in the backend RHAAP/AWX server Operation type Type of operation (Create, update, delete). Change the state of he instance after executing the operation Process timeout Number of second to wait for a successful return from the executed job template Auto accept If set to True a submitted request for this operation will be automatically accepted Auto process If set to True an accepted request for this operation will be automatically processed Enabled If set to True the operation can be requested from the UI and API Admin operation If set to True the admin_request_on_instance permission is required to request this operation Extra vars Set of extra vars as JSON Default inventory ID ID of the RHAAP/AWX inventory to use by default. Leave blank to use the default Job Template inventory Default limit Comma separated list of inventory host limits Default tags Comma separated list of tags to use Default skip tags Comma separated list of tags to skip Default verbosity Verbosity level (integer) Default job type Job type (Run or Check) Default diff mode Default False . This is equivalent to Ansible's --diff mode in the CLI Default credential IDs Comma separated list of credentials ID","title":"Configuration"},{"location":"manual/service_catalog/operation/#job-template-config","text":"By default, Squest will execute the selected Job Template with the config as set in RHAAP/AWX. If a field is configured to \"Prompt on launch\" in RHAAP/AWX, the administrator can override it from the \"Process\" page of an accepted request: Overridable fields: Inventory (ID) Limit (hosts) Tags Skip tags Verbosity Job type Diff mode (Show changes) Credentials (Comma separated list of ID) The \"default\" configuration set at operation level allow to automatically pre-fill the \"Process\" page with values. Jinja templating can be used in the default value based on the current {{ request }} object as context. Examples can be retrieved in the dedicated documentation section . Full request object definition can be retrieved through the API documentation . Default value precedence: flowchart LR RHAAP/AWX(Default from RHAAP/AWX) --> Squest(Default from Squest) --> Process(Process request page) Note Default inventory ID field is expecting an integer that correspond the the inventory ID in RHAAP/AWX. Default credential IDs field is expecting a comma separated list of integer that correspond existings credentials ID in RHAAP/AWX.","title":"Job template config"},{"location":"manual/service_catalog/service/","text":"Service A service in Squest is an item of the catalog. It contains at least one operation to create (or instantiate) the service and multiple day 2 operations to update or delete an already created instance of this service. Configuration Name Description Name Short name of the service Description Small description of the operation Image Image used into the catalog Enabled If set to True the service is visible in the catalog External support URL Define an external support tool URL Extra vars Set of extra vars as JSON Description documentation Markdown documentation linked to the service External support URL Squest has an integrated support management. End user can open a support ticket on available instances. An external url can be defined as support tool in each service configuration. This allows to configure for example a redirection to services like GitHub issues or Jira. The external support URL support jinja templating to insert the current instance metadata as query parameters. E.g: http://my_external_tool.domain.local/?instance_name={{ instance.name }}?instance_id={{ instance.id }}?vm_os={{ instance.spec.vm_os }} Example with Github issue query parameters : https://github.com/HewlettPackard/squest/issues/new?title=Templated+Github+issue&body=Instance%3A+{{ instance.name }} Note Special characters need to be converted into a format that can be transmitted over the Internet. URLs can only be sent over the Internet using the ASCII character-set. Extra vars Some extra variables can be declared on some Squest level like tower_server , service or operation . These extra variables are added automatically when processing a request and so executing a job template. If an extra variable is set with the same name in different places, the variable will be overridden following a certain order. Squest will apply the following variable precedence: flowchart LR survey(Request survey) --> RHAAP/AWX(RHAAP/AWX) --> Service(Service) --> Operation(Operation)","title":"Service"},{"location":"manual/service_catalog/service/#service","text":"A service in Squest is an item of the catalog. It contains at least one operation to create (or instantiate) the service and multiple day 2 operations to update or delete an already created instance of this service.","title":"Service"},{"location":"manual/service_catalog/service/#configuration","text":"Name Description Name Short name of the service Description Small description of the operation Image Image used into the catalog Enabled If set to True the service is visible in the catalog External support URL Define an external support tool URL Extra vars Set of extra vars as JSON Description documentation Markdown documentation linked to the service","title":"Configuration"},{"location":"manual/service_catalog/service/#external-support-url","text":"Squest has an integrated support management. End user can open a support ticket on available instances. An external url can be defined as support tool in each service configuration. This allows to configure for example a redirection to services like GitHub issues or Jira. The external support URL support jinja templating to insert the current instance metadata as query parameters. E.g: http://my_external_tool.domain.local/?instance_name={{ instance.name }}?instance_id={{ instance.id }}?vm_os={{ instance.spec.vm_os }} Example with Github issue query parameters : https://github.com/HewlettPackard/squest/issues/new?title=Templated+Github+issue&body=Instance%3A+{{ instance.name }} Note Special characters need to be converted into a format that can be transmitted over the Internet. URLs can only be sent over the Internet using the ASCII character-set.","title":"External support URL"},{"location":"manual/service_catalog/service/#extra-vars","text":"Some extra variables can be declared on some Squest level like tower_server , service or operation . These extra variables are added automatically when processing a request and so executing a job template. If an extra variable is set with the same name in different places, the variable will be overridden following a certain order. Squest will apply the following variable precedence: flowchart LR survey(Request survey) --> RHAAP/AWX(RHAAP/AWX) --> Service(Service) --> Operation(Operation)","title":"Extra vars"},{"location":"manual/service_catalog/survey/","text":"Survey The survey of an operation in Squest is actually the one configured in the RHAAP/AWX job templates. Squest administrator can select which fields will be exposed to the end users when requesting a service or a day 2 operation. By default, the approval workflow is composed of 2 steps: Customer form (fields noted as 'customer field') Admin form (All fields of the job template) If more steps are needed, you can create a dedicated approval workflow . Is customer field A customer field is a field that will be displayed into the end user survey. By default, all fields are enabled when creating a new operation. Fields that are not customer fields can be filled by any users who have the accept_request permission. Note If the field is set as required into the RHAAP/AWX job template survey config then the administrator will have to fill it in any case during the review of the request. Default value When set, the default value is pre-filled into the final form. It takes precedence over the default value set in RHAAP/AWX job template survey config. Default value precedence: flowchart LR RHAAP/AWX(Default from RHAAP/AWX) --> squest(Default from Squest value) --> User(User's input) --> Admin(Admin's input) Note When used with a 'multiple select' or 'multiple select multiple' type of field, the value need to be a valid one from the RHAAP/AWX survey field options. Jinja templating Jinja templating can be used in the default value based on the current {{ instance }} and {{ user }} objects as context. Examples can be retrieved in the dedicated documentation section . Full instance and user object definition can be retrieved through the API documentation . Validators Field validators are python modules that can be added as plugin to perform a custom check on a form field. See related documentation here . Attribute definition Each field can be linked to an Attribute definition from the resource tracking. This allows to automatically limit the field value to a quota . The available quota is shown in the form of the request so the end user know what he can still consume.","title":"Survey"},{"location":"manual/service_catalog/survey/#survey","text":"The survey of an operation in Squest is actually the one configured in the RHAAP/AWX job templates. Squest administrator can select which fields will be exposed to the end users when requesting a service or a day 2 operation. By default, the approval workflow is composed of 2 steps: Customer form (fields noted as 'customer field') Admin form (All fields of the job template) If more steps are needed, you can create a dedicated approval workflow .","title":"Survey"},{"location":"manual/service_catalog/survey/#is-customer-field","text":"A customer field is a field that will be displayed into the end user survey. By default, all fields are enabled when creating a new operation. Fields that are not customer fields can be filled by any users who have the accept_request permission. Note If the field is set as required into the RHAAP/AWX job template survey config then the administrator will have to fill it in any case during the review of the request.","title":"Is customer field"},{"location":"manual/service_catalog/survey/#default-value","text":"When set, the default value is pre-filled into the final form. It takes precedence over the default value set in RHAAP/AWX job template survey config. Default value precedence: flowchart LR RHAAP/AWX(Default from RHAAP/AWX) --> squest(Default from Squest value) --> User(User's input) --> Admin(Admin's input) Note When used with a 'multiple select' or 'multiple select multiple' type of field, the value need to be a valid one from the RHAAP/AWX survey field options. Jinja templating Jinja templating can be used in the default value based on the current {{ instance }} and {{ user }} objects as context. Examples can be retrieved in the dedicated documentation section . Full instance and user object definition can be retrieved through the API documentation .","title":"Default value"},{"location":"manual/service_catalog/survey/#validators","text":"Field validators are python modules that can be added as plugin to perform a custom check on a form field. See related documentation here .","title":"Validators"},{"location":"manual/service_catalog/survey/#attribute-definition","text":"Each field can be linked to an Attribute definition from the resource tracking. This allows to automatically limit the field value to a quota . The available quota is shown in the form of the request so the end user know what he can still consume.","title":"Attribute definition"}]}